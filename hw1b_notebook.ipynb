{"cells":[{"cell_type":"markdown","metadata":{},"source":["# Libraries Required"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:13:39.666795Z","iopub.status.busy":"2024-05-03T19:13:39.665787Z","iopub.status.idle":"2024-05-03T19:13:39.765235Z","shell.execute_reply":"2024-05-03T19:13:39.764340Z","shell.execute_reply.started":"2024-05-03T19:13:39.666758Z"},"id":"LxMvKgA8z7ch","trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["d:\\Anaconda\\lib\\site-packages\\scipy\\__init__.py:146: UserWarning: A NumPy version >=1.16.5 and <1.23.0 is required for this version of SciPy (detected version 1.24.0\n","  warnings.warn(f\"A NumPy version >={np_minversion} and <{np_maxversion}\"\n"]}],"source":["import pandas as pd\n","import torch\n","from matplotlib import pyplot as plt\n","import spacy\n","import numpy as np\n","import torch\n","from torch import nn\n","from torch.nn import functional as F\n","from torch.nn.utils.rnn import pad_sequence\n","from torch.utils.data import Dataset, DataLoader\n","from torch.nn.utils.rnn import pack_padded_sequence,pad_packed_sequence\n","import re\n","import random\n","from collections import defaultdict\n","from sklearn.metrics import precision_score, recall_score, f1_score\n","from sklearn.metrics import confusion_matrix\n","from copy import deepcopy\n","from sklearn.metrics import confusion_matrix\n","import seaborn as sns\n"]},{"cell_type":"markdown","metadata":{},"source":["# set torch seeed"]},{"cell_type":"code","execution_count":2,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:42:32.102913Z","iopub.status.busy":"2024-05-03T18:42:32.101940Z","iopub.status.idle":"2024-05-03T18:42:32.111572Z","shell.execute_reply":"2024-05-03T18:42:32.110475Z","shell.execute_reply.started":"2024-05-03T18:42:32.102873Z"},"trusted":true},"outputs":[],"source":["def set_seed(seed):\n","    torch.manual_seed(seed)\n","    torch.cuda.manual_seed_all(seed)\n","    torch.backends.cudnn.deterministic = True\n","    torch.backends.cudnn.benchmark = False\n","    np.random.seed(seed)\n","    random.seed(seed)\n","\n","# Set the seed\n","seed = 42  # You can use any integer value\n","set_seed(seed)"]},{"cell_type":"markdown","metadata":{"id":"npZ1jsYV0Xua"},"source":["### Splitting the train.json to Train and Val\n","> #### For performing evaluation of the model.\n","> #### Performing Hyperparameter Search"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:42:32.116089Z","iopub.status.busy":"2024-05-03T18:42:32.115815Z","iopub.status.idle":"2024-05-03T18:42:32.183805Z"},"id":"uEXtvxKw0Wv7","outputId":"2d48cfe5-ca11-4087-b370-653610611265","trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>sentence-id</th>\n","      <th>text</th>\n","      <th>choices</th>\n","      <th>labels</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0</td>\n","      <td>CONTRORDINE COMPAGNI.\\nFATE GIRARE LA VOCE CHE...</td>\n","      <td>[Contro, Favore, Neutrale]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>A proposito dell'incontro delle @6000sardine c...</td>\n","      <td>[Contro, Favore, Neutrale]</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>2</td>\n","      <td>Care sardine che richiamate in continuazione i...</td>\n","      <td>[Contro, Favore, Neutrale]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>3</td>\n","      <td>Domanda ad una sardina \" secondo te Qual è il ...</td>\n","      <td>[Contro, Favore, Neutrale]</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>4</td>\n","      <td>A salvini non gli frega nulla delle sardine no...</td>\n","      <td>[Contro, Favore, Neutrale]</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>2127</th>\n","      <td>2127</td>\n","      <td>Pidini non montatevi la testa, non avete perso...</td>\n","      <td>[Contro, Favore, Neutrale]</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2128</th>\n","      <td>2128</td>\n","      <td>Volete sapere perché il pd nonostante tutto di...</td>\n","      <td>[Contro, Favore, Neutrale]</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2129</th>\n","      <td>2129</td>\n","      <td>#Omnibusla7 Telese in piena fregola per il cap...</td>\n","      <td>[Contro, Favore, Neutrale]</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2130</th>\n","      <td>2130</td>\n","      <td>Noto con piacere che le librerie si stanno rip...</td>\n","      <td>[Contro, Favore, Neutrale]</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>2131</th>\n","      <td>2131</td>\n","      <td>Il Pd quasi al 35% in Emilia Romagna. E non ag...</td>\n","      <td>[Contro, Favore, Neutrale]</td>\n","      <td>2</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>2132 rows × 4 columns</p>\n","</div>"],"text/plain":["      sentence-id                                               text  \\\n","0               0  CONTRORDINE COMPAGNI.\\nFATE GIRARE LA VOCE CHE...   \n","1               1  A proposito dell'incontro delle @6000sardine c...   \n","2               2  Care sardine che richiamate in continuazione i...   \n","3               3  Domanda ad una sardina \" secondo te Qual è il ...   \n","4               4  A salvini non gli frega nulla delle sardine no...   \n","...           ...                                                ...   \n","2127         2127  Pidini non montatevi la testa, non avete perso...   \n","2128         2128  Volete sapere perché il pd nonostante tutto di...   \n","2129         2129  #Omnibusla7 Telese in piena fregola per il cap...   \n","2130         2130  Noto con piacere che le librerie si stanno rip...   \n","2131         2131  Il Pd quasi al 35% in Emilia Romagna. E non ag...   \n","\n","                         choices  labels  \n","0     [Contro, Favore, Neutrale]       0  \n","1     [Contro, Favore, Neutrale]       2  \n","2     [Contro, Favore, Neutrale]       0  \n","3     [Contro, Favore, Neutrale]       0  \n","4     [Contro, Favore, Neutrale]       2  \n","...                          ...     ...  \n","2127  [Contro, Favore, Neutrale]       2  \n","2128  [Contro, Favore, Neutrale]       2  \n","2129  [Contro, Favore, Neutrale]       2  \n","2130  [Contro, Favore, Neutrale]       2  \n","2131  [Contro, Favore, Neutrale]       2  \n","\n","[2132 rows x 4 columns]"]},"execution_count":4,"metadata":{},"output_type":"execute_result"}],"source":["#### read the train.json\n","train_val=pd.read_json('./data//subtask_1-train.jsonl',lines=True)\n","### read the test.json\n","test_data=pd.read_json('./data/subtask_1-test.jsonl',lines=True)\n","### split the dataset into 90/20 split\n","train_val"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:43:35.481773Z","iopub.status.busy":"2024-05-03T18:43:35.481078Z","iopub.status.idle":"2024-05-03T18:43:35.872830Z","shell.execute_reply":"2024-05-03T18:43:35.871462Z","shell.execute_reply.started":"2024-05-03T18:43:35.481738Z"},"id":"WV_RnxP_P9b4","trusted":true},"outputs":[],"source":["\n","\n","def custom_train_val_split(data, test_size=0.1):\n","    \"\"\"\n","    Custom train/validation split function without using scikit-learn.\n","    \"\"\"\n","    # Shuffle the DataFrame to ensure randomness\n","    data_shuffled = data.sample(frac=1, random_state=42)\n","\n","    # Group the DataFrame by the label column\n","    grouped = data_shuffled.groupby('labels')\n","\n","    # Initialize empty DataFrames for train and validation sets\n","    train_data = pd.DataFrame()\n","    val_data = pd.DataFrame()\n","\n","    # For each group, split the data into train and validation sets\n","    for label, group in grouped:\n","        # Calculate the number of samples for validation set\n","        num_val_samples = int(len(group) * test_size)\n","\n","        # Select samples for validation set\n","        val_group = group.iloc[:num_val_samples]\n","\n","        # Select remaining samples for train set\n","        train_group = group.iloc[num_val_samples:]\n","\n","        # Concatenate the train and validation sets\n","        train_data = pd.concat([train_data, train_group])\n","        val_data = pd.concat([val_data, val_group])\n","\n","    # Reset index for the new DataFrames\n","    train_data.reset_index(drop=True, inplace=True)\n","    train_data=train_data.sample(frac=1,random_state=420)\n","    val_data.reset_index(drop=True, inplace=True)\n","    val_data=val_data.sample(frac=1,random_state=420)\n","\n","    return train_data, val_data\n","\n","### get the splits\n","train_data, val_data = custom_train_val_split(train_val, test_size=0.2)\n","del train_val"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:43:35.884073Z","iopub.status.busy":"2024-05-03T18:43:35.883757Z","iopub.status.idle":"2024-05-03T18:43:36.454875Z","shell.execute_reply":"2024-05-03T18:43:36.453781Z","shell.execute_reply.started":"2024-05-03T18:43:35.884046Z"},"id":"ysiysDE11eva","outputId":"1d6bd55f-1b59-4b67-c999-feb414fa69d7","trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 1200x600 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["def plot_dist_labels(data: pd.DataFrame, ax, title: str):\n","    \"\"\"\n","    Function to plot the distribution of the classes in a given dataframe\n","    \"\"\"\n","    label_counts = data['labels'].value_counts(normalize=True)\n","    label_counts.plot(kind='bar', title=title, ax=ax)\n","    ax.set_xlabel('Labels')\n","    ax.set_ylabel('Probability')\n","    ax.spines[['top', 'right']].set_visible(False)\n","\n","# Create a figure with two subplots\n","fig, axs = plt.subplots(1, 2, figsize=(12, 6))\n","\n","# Plot class distribution for train set\n","plot_dist_labels(train_data, axs[0], title='Train Set Distribution')\n","\n","# Plot class distribution for validation set\n","plot_dist_labels(val_data, axs[1], title='Validation Set Distribution')\n","\n","# Adjust layout\n","plt.tight_layout()\n","plt.show()\n"]},{"cell_type":"markdown","metadata":{"id":"Ohy5I9sJR_by"},"source":["> #### It's a choice that I made to implement a function for stratified spliiting instead of using sklearn train_test_split function for stratified sampling.\n","> #### We can clearly see the distribution among the classes are maintained during the split from the above plots"]},{"cell_type":"markdown","metadata":{"id":"UjklAt7OTjpX"},"source":["# Tokenisation,Vocab,Embedding -Spacy Lib\n","\n","> #### 1. using it_core_news_lg(large) based model[https://spacy.io/models/it#it_core_news_lg] with 300dim of vectors\n"]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:43:37.585574Z","iopub.status.busy":"2024-05-03T18:43:37.584798Z","iopub.status.idle":"2024-05-03T18:44:05.390908Z","shell.execute_reply":"2024-05-03T18:44:05.389877Z","shell.execute_reply.started":"2024-05-03T18:43:37.585524Z"},"id":"GIXbyMToTi2L","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Collecting it-core-news-lg==3.7.0\n","  Downloading https://github.com/explosion/spacy-models/releases/download/it_core_news_lg-3.7.0/it_core_news_lg-3.7.0-py3-none-any.whl (567.9 MB)\n","\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m567.9/567.9 MB\u001b[0m \u001b[31m2.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n","\u001b[?25hRequirement already satisfied: spacy<3.8.0,>=3.7.0 in /opt/conda/lib/python3.10/site-packages (from it-core-news-lg==3.7.0) (3.7.3)\n","Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (3.0.12)\n","Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (1.0.5)\n","Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (1.0.10)\n","Requirement already satisfied: cymem<2.1.0,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (2.0.8)\n","Requirement already satisfied: preshed<3.1.0,>=3.0.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (3.0.9)\n","Requirement already satisfied: thinc<8.3.0,>=8.2.2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (8.2.2)\n","Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (1.1.2)\n","Requirement already satisfied: srsly<3.0.0,>=2.4.3 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (2.4.8)\n","Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (2.0.10)\n","Requirement already satisfied: weasel<0.4.0,>=0.1.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (0.3.4)\n","Requirement already satisfied: typer<0.10.0,>=0.3.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (0.9.0)\n","Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (6.4.0)\n","Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (4.66.1)\n","Requirement already satisfied: requests<3.0.0,>=2.13.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (2.31.0)\n","Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (2.5.3)\n","Requirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (3.1.2)\n","Requirement already satisfied: setuptools in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (69.0.3)\n","Requirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (21.3)\n","Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (3.3.0)\n","Requirement already satisfied: numpy>=1.19.0 in /opt/conda/lib/python3.10/site-packages (from spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (1.26.4)\n","Requirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (3.1.1)\n","Requirement already satisfied: annotated-types>=0.4.0 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (0.6.0)\n","Requirement already satisfied: pydantic-core==2.14.6 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (2.14.6)\n","Requirement already satisfied: typing-extensions>=4.6.1 in /opt/conda/lib/python3.10/site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (4.9.0)\n","Requirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (3.3.2)\n","Requirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (3.6)\n","Requirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (1.26.18)\n","Requirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (2024.2.2)\n","Requirement already satisfied: blis<0.8.0,>=0.7.8 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (0.7.10)\n","Requirement already satisfied: confection<1.0.0,>=0.0.1 in /opt/conda/lib/python3.10/site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (0.1.4)\n","Requirement already satisfied: click<9.0.0,>=7.1.1 in /opt/conda/lib/python3.10/site-packages (from typer<0.10.0,>=0.3.0->spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (8.1.7)\n","Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in /opt/conda/lib/python3.10/site-packages (from weasel<0.4.0,>=0.1.0->spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (0.16.0)\n","Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->spacy<3.8.0,>=3.7.0->it-core-news-lg==3.7.0) (2.1.3)\n","\u001b[38;5;2m✔ Download and installation successful\u001b[0m\n","You can now load the package via spacy.load('it_core_news_lg')\n"]}],"source":["### get it_core_news_lg\n","\n","!python -m spacy download it_core_news_lg"]},{"cell_type":"markdown","metadata":{},"source":["### Spacy Model\n","> #### Get the vocabualary and the vectors"]},{"cell_type":"code","execution_count":11,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:44:05.393286Z","iopub.status.busy":"2024-05-03T18:44:05.392962Z","iopub.status.idle":"2024-05-03T18:44:32.991038Z","shell.execute_reply":"2024-05-03T18:44:32.989973Z","shell.execute_reply.started":"2024-05-03T18:44:05.393258Z"},"id":"nRfChcVuZMyC","outputId":"8e81d54c-27bf-4f40-999b-19884d8f87cb","trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Number of words:681834,Shape of embeddings:(681834, 300)\n"]}],"source":["nlp_ = spacy.load(\"it_core_news_lg\")\n","#Get the vocabulary from the loaded italian spaCy model\n","words_list = list(nlp_.vocab.strings)\n","### get the vectors for the vocab words\n","vectors = [nlp_.vocab.get_vector(word) for word in words_list]\n","\n","# Convert the list of vectors into a numpy array[Usage to intialiase embedding layer]\n","embeddings = np.array(vectors)\n","### remove redundant variables from memmory\n","del vectors\n","# Final Check\n","print(\"Number of words:{},Shape of embeddings:{}\".format(len(words_list),embeddings.shape))"]},{"cell_type":"markdown","metadata":{},"source":["> #### Add the vectors for pad and unk token"]},{"cell_type":"code","execution_count":12,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:44:32.992691Z","iopub.status.busy":"2024-05-03T18:44:32.992309Z","iopub.status.idle":"2024-05-03T18:44:33.436935Z","shell.execute_reply":"2024-05-03T18:44:33.435727Z","shell.execute_reply.started":"2024-05-03T18:44:32.992662Z"},"trusted":true},"outputs":[],"source":["pad_vec=np.random.normal(size=(1,embeddings.shape[1]))\n","unk_vec=np.random.normal(size=(1,embeddings.shape[1]))\n","embeddings=np.concatenate((pad_vec,unk_vec,embeddings),axis=0)"]},{"cell_type":"markdown","metadata":{},"source":["# Character Dictiionary-Vocabulary for Character Based Embedding "]},{"cell_type":"code","execution_count":13,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:44:33.439988Z","iopub.status.busy":"2024-05-03T18:44:33.439559Z","iopub.status.idle":"2024-05-03T18:44:33.447373Z","shell.execute_reply":"2024-05-03T18:44:33.446326Z","shell.execute_reply.started":"2024-05-03T18:44:33.439951Z"},"trusted":true},"outputs":[],"source":["###character dict\n","char_list=list(\n","            \"\"\"ABCDEFGHIJKLMNOPQRSTUVWXYZabcdefghijklmnopqrstuvwxyzàèéìíîòóùûüÀÈÉÌÍÎÒÓÙÛÜ0123456789,;.!?:'\\\"/\\\\|_@#$%^&*~`+-=<>()[]\"\"\"\n",")\n","char_dict=defaultdict()\n","\n","char_dict['<pad>']=0\n","char_dict['<unk>']=1\n","\n","for i,j in enumerate(char_list):\n","\n","    char_dict[j]=i+2"]},{"cell_type":"markdown","metadata":{"id":"EsKVKlu-bH7V"},"source":["# Create Vocabulary Class\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:44:33.449101Z","iopub.status.busy":"2024-05-03T18:44:33.448801Z","iopub.status.idle":"2024-05-03T18:44:33.839949Z","shell.execute_reply":"2024-05-03T18:44:33.839052Z","shell.execute_reply.started":"2024-05-03T18:44:33.449075Z"},"id":"Tx6p70etbFxu","trusted":true},"outputs":[],"source":["\n","class Vocabulary:\n","\n","    def __init__(self,vocab_):\n","\n","        ### From index getting the token\n","        self.itos={}\n","        ### From token to Index\n","        self.stoi={}\n","        ### Size of the vocabulary\n","        self.size=len(vocab_)\n","        ### Storing the vocabulary\n","        self.vocab=vocab_\n","\n","        ### padding token\n","        self.pad_token='<pad>'\n","        ### pre-trained embeddings[used in the spacy model] already handle the case of the unknown token via 'oov' token\n","#         #### unknown token\n","        self.unk_token='<unk>'\n","\n","        #### stop words\n","        self.stop_words=nlp_.Defaults.stop_words\n","        \n","        ### embeddings\n","        self.embedding=None\n","\n","\n","    def indexed_vocab(self):\n","        \"\"\"\"\"\n","        Building Index Dictionay of words Position in the vocbulary.This would help in fast retrieval of vectorial representation of\n","        the words( and vice-versa)\n","        \"\"\"\"\"\n","        ### First adding info regarding <pad>  token\n","        self.itos[0]='<pad>'\n","        self.itos[1]='<unk>'\n","\n","        self.stoi['<pad>']=0\n","        self.stoi['<unk>']=1\n","\n","        #### iterate over vocab now\n","        for i,j in enumerate(self.vocab):\n","\n","            ## Index to string\n","            self.itos[i+2]=j\n","\n","            ## String to Index\n","            self.stoi[j]=i+2\n","\n","   \n","\n","vocab_it=Vocabulary(words_list)\n","### index the vocabulary\n","vocab_it.indexed_vocab()\n","### now i can remove the list of the words\n","del words_list\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["# Parts-of-Speech tag Vocabulary"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:44:33.841725Z","iopub.status.busy":"2024-05-03T18:44:33.841306Z","iopub.status.idle":"2024-05-03T18:44:33.851484Z","shell.execute_reply":"2024-05-03T18:44:33.850439Z","shell.execute_reply.started":"2024-05-03T18:44:33.841687Z"},"trusted":true},"outputs":[],"source":["class VocabPos:\n","    def __init__(self, pos_tags):\n","        # Store POS tags\n","        self.pos_tags = pos_tags\n","        # Initialize index dictionaries\n","        self.itos = {}\n","        self.stoi = {}\n","        # Build index dictionaries\n","        self.index_pos()\n","        ### size of the pos tag\n","        self.size=len(self.itos)\n","\n","    def index_pos(self):\n","        # Add special tokens to dictionaries\n","        self.itos[0] = '<pad>'\n","        self.itos[1] = '<unk>'\n","        self.stoi['<pad>'] = 0\n","        self.stoi['<unk>'] = 1\n","        # Index POS tags\n","        for i, pos_tag in enumerate(self.pos_tags):\n","            self.itos[i + 2] = pos_tag\n","            self.stoi[pos_tag] = i + 2\n","            \n","all_pos_tags = [\n","    'ADJ', 'ADP', 'ADV', 'AUX', 'CONJ', 'CCONJ', 'DET', 'INTJ', 'NOUN', 'NUM',\n","    'PART', 'PRON', 'PROPN', 'PUNCT', 'SCONJ', 'SYM', 'VERB', 'X'\n","]\n","\n","# Create a VocabPos instance\n","pos_vocab = VocabPos(all_pos_tags)\n","\n"]},{"cell_type":"markdown","metadata":{"id":"ai-jSDM7Yx58"},"source":["# Custom Dataset\n","\n","> #### Usage of collate function to handle non-equal length of text"]},{"cell_type":"code","execution_count":16,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:48:59.220368Z","iopub.status.busy":"2024-05-03T18:48:59.219766Z","iopub.status.idle":"2024-05-03T18:49:32.834342Z","shell.execute_reply":"2024-05-03T18:49:32.833388Z","shell.execute_reply.started":"2024-05-03T18:48:59.220337Z"},"id":"jNcE7YJnYvgS","trusted":true},"outputs":[],"source":["class SST2Dataset(Dataset):\n","    def __init__(\n","        self,\n","        input_df: pd.DataFrame,\n","        max_length: int = 1028,\n","        device: str = \"cuda\"\n","    ):\n","        \n","\n","        # Save samples from input file\n","        self.data = input_df.loc[:,['sentence-id','text','labels']]\n","        \n","\n","        # Initialize indexed data attribute but leave it None\n","        # Must be filled through the `.index(vocabulary, label_vocabulary)` method\n","        # each dictionary represents a sentence with two keys: \"input_ids\" and \"label\"\n","        self.indexed_data: list[dict] | None = None\n","\n","        # Keep track of the maximum length to allow for a batch\n","        self.max_length = max_length\n","\n","        # Save device\n","        self.device = torch.device(device)\n","\n","        # intialiase the padding id\n","        self.padding_id=0\n","        # Initialize POS vocabulary\n","        self.pos_vocab = None\n","\n","\n","    def get_raw_element(self, idx: int) -> dict:\n","        \"\"\"Utility function that gets the raw sample corresponding to `idx`.\"\"\"\n","        return self.data.iloc[idx].to_dict()\n","\n","    def __len__(self) -> int:\n","        return len(self.data)\n","\n","    def __getitem__(self, idx: int) -> dict:\n","        if self.indexed_data is None:\n","            raise RuntimeError(\n","                \"Trying to retrieve samples but dataset has not been indexed yet!\"\n","                + \" Be sure to call `.index()` on this object.\"\n","                + \" If you want to retrieve raw elements, call `.get_raw_elements(idx)\"\n","            )\n","        return self.indexed_data[idx]\n","    def remove_special_chars(self,text):\n","        # Define the regex pattern to match punctuations, special symbols, and numbers\n","        pattern = r'[\\W\\d_]+'\n","        # Substitute the pattern with an empty string\n","        cleaned_text = re.sub(pattern, ' ', text)\n","        return cleaned_text\n","    \n","    def preprocess_tokenise(self,text:str):\n","        \"\"\"\"\"\n","        this function preprocess and converts the string into list of tokens\n","        \n","        \"\"\"\"\"\n","        ####  process the text\n","        text=self.remove_special_chars(text)\n","        t=nlp_(text)\n","        ### remove the stop words and get the lemmas\n","        tokens_final=[i for i in t if i.text.lower() not in vocab_it.stop_words]\n","        ### get the pos tags\n","        pos_tags = [token.pos_ for token in tokens_final]\n","        return tokens_final, pos_tags\n","\n","    def index(self, vocabulary: Vocabulary,pos_vocabulary:VocabPos) -> None:\n","        \"\"\"Builds `self.indexed_data` by converting raw samples to input_ids following `vocabulary`\"\"\"\n","        if self.indexed_data is not None:\n","            print(\"Dataset has already been indexed. Keeping old index...\")\n","        else:\n","            indexed_data = []\n","            self.pos_vocab=pos_vocabulary\n","            ### iterate over the dataset\n","            for i,sample in self.data.iterrows():\n","                \n","                #### Tokenisation of text \n","                tokens,pos_tags=self.preprocess_tokenise(sample['text'])\n","                ### Tokens to ids\n","                token_ids=[vocabulary.stoi.get(j.lemma_.lower(),vocabulary.stoi['<unk>'])  for j in tokens]\n","                \n","                ###tokens to  pos tag indices\n","                pos_tag_indices = [self.pos_vocab.stoi.get(j, self.pos_vocab.stoi['<unk>']) for j in pos_tags]\n","               \n","\n","                # append the dictionary containing ids of the input tokens and label\n","                indexed_data.append({\"input_ids\":token_ids,\"pos_tags\":pos_tag_indices, \"labels\": sample[\"labels\"]})\n","            self.indexed_data = indexed_data\n","    \n","    def handle_unk(self,j,vocabulary):\n","        \"\"\"\n","        Hanld unk case\n","        \"\"\"\n","        ### if lemma form embedding is not found in the vocabulary,first check if there is vector in original form otherwise return 'oov' embedding (zero vec)\n","        \n","        \n","        return vocabulary.stoi.get(j.text.lower(),vocabulary.stoi['<unk>'])\n","    \n","    def _collate_fn(self,raw_batch: list[dict]) -> tuple[torch.Tensor, torch.Tensor, torch.Tensor]:\n","        \"\"\"\n","        Batches together single elements of the dataset.\n","        This function:\n","        - converts each sentence made up of single input_ids to a padded tensor,\n","        - keeps track of the length of each sentence through `sequence_lengths`\n","        - builds a `labels` tensor storing the label for each sentence\n","\n","        Args:\n","            raw_batch (list[dict]): a list of elements, as returned by the `__getitem__()` function.\n","\n","        Returns:\n","            A tuple of three tensors, respectively `(sequence_lengths, padded_sequence, labels)`\n","        \"\"\"\n","        if self.padding_id is None:\n","            raise RuntimeError(\"Padding value not set! Set it through .set_padding_id method.\")\n","\n","        # We need these sequence lengths to construct a `torch.nn.utils.rnn.PackedSequence` in the model\n","        sequence_lengths = torch.tensor([len(sample[\"input_ids\"]) for sample in raw_batch], dtype=torch.long)\n","        ### padding the seq's to common length\n","        padded_sequence = pad_sequence(\n","            (\n","                torch.tensor(sample[\"input_ids\"], dtype=torch.long, device=self.device)\n","                for sample in raw_batch\n","            ),\n","            batch_first=True,\n","            padding_value=self.padding_id\n","        )\n","        ### getting the tensor array of labels for the batch\n","        labels = torch.tensor([sample[\"labels\"] for sample in raw_batch], device=self.device, dtype=torch.long)\n","        \n","        \n","        # Pad POS tag indices\n","        padded_pos_tags = pad_sequence(\n","            (\n","                torch.tensor(sample[\"pos_tags\"], dtype=torch.long, device=self.device)\n","                for sample in raw_batch\n","            ),\n","            batch_first=True,\n","            padding_value=self.padding_id\n","        )\n","        \n","        return sequence_lengths, padded_sequence, labels,padded_pos_tags\n","        \n","\n","#### create training dataset\n","train_dataset=SST2Dataset(train_data)\n","### indexing \n","train_dataset.index(vocab_it,pos_vocab)\n","#### create validation dataset\n","val_dataset=SST2Dataset(val_data)\n","### indexing \n","val_dataset.index(vocab_it,pos_vocab)\n","\n","#### create test dataset\n","test_dataset=SST2Dataset(test_data)\n","##indexing\n","test_dataset.index(vocab_it,pos_vocab)\n"]},{"cell_type":"code","execution_count":17,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:49:32.836513Z","iopub.status.busy":"2024-05-03T18:49:32.836120Z","iopub.status.idle":"2024-05-03T18:49:32.843574Z","shell.execute_reply":"2024-05-03T18:49:32.842470Z","shell.execute_reply.started":"2024-05-03T18:49:32.836481Z"},"trusted":true},"outputs":[],"source":["#### create train/val/test dataloader\n","train_dataloader = DataLoader(train_dataset, batch_size=128, shuffle=True, collate_fn=train_dataset._collate_fn)\n","val_dataloader = DataLoader(val_dataset, batch_size=128, shuffle=False, collate_fn=val_dataset._collate_fn\n","                           )\n","test_dataloader = DataLoader(test_dataset, batch_size=128, shuffle=False, collate_fn=test_dataset._collate_fn\n","                           )"]},{"cell_type":"markdown","metadata":{},"source":["# Main Model"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:58:48.220015Z","iopub.status.busy":"2024-05-03T18:58:48.219187Z","iopub.status.idle":"2024-05-03T18:58:48.472765Z","shell.execute_reply":"2024-05-03T18:58:48.471799Z","shell.execute_reply.started":"2024-05-03T18:58:48.219977Z"},"trusted":true},"outputs":[],"source":["#### Model-1 Fixed Embedding[static+BILSTM+Projection layer]\n","class model_v1(torch.nn.Module):\n","\n","    def __init__(\n","        self,\n","        vocabulary: Vocabulary,\n","        embeddings:np.array,\n","        hidden_dim_lstm_fac: int,\n","        bilstm_layers: int,\n","        dropout: float,\n","        num_classes: int,\n","        padding_id: int,\n","        freeze_embedding:bool,\n","        char_embed_bool:bool,\n","        char_embed_dim:int,\n","        char_kernel_size:int,\n","        cnn_lstm_bool:bool,\n","        average_tokens:bool,\n","        char_dict:dict,\n","        pos_vocab: VocabPos, \n","        pos_embed_dim: int,  \n","        pos_embed_bool: bool,\n","        recurrent_type:str,\n","        device: str = \"cuda\",\n","    ) -> None:\n","        super().__init__()\n","\n","        # Prepare the device\n","        self.device = torch.device(device)\n","        \n","        #### vocabulary\n","        self.vocab=vocabulary\n","\n","        # Embedding layer\n","        self.embedding = nn.Embedding(\n","            num_embeddings=vocabulary.size+2,\n","            embedding_dim=embeddings.shape[1],\n","            padding_idx=padding_id, # avoid updating the gradient of padding entries\n","            device=self.device\n","        )\n","         #Load weights from the NumPy array\n","        self.embedding.weight.data.copy_(torch.from_numpy(embeddings))\n","        if freeze_embedding:\n","            self.embedding.weight.requires_grad=False\n","       \n","        \n","        ### Use characeter based embedding\n","        self.char_embed_bool=char_embed_bool\n","        if self.char_embed_bool:\n","            self.char_dict=char_dict\n","            ### character based embedding size\n","            self.char_embed_dim=char_embed_dim\n","            self.embedding_1=nn.Embedding(len(char_dict),self.char_embed_dim,device=self.device)\n","            ### word embedding using charcter embeddings. Using same dim as character embedding\n","            self.word_char_emb=char_embed_dim\n","            self.char_kernel_size=char_kernel_size\n","            self.cnn=nn.Conv2d(in_channels=1, out_channels=self.word_char_emb, kernel_size=(char_kernel_size, self.char_embed_dim), padding=(0,0),device=self.device)\n","        else:\n","            self.word_char_emb=0\n","            \n","        #POS tag embedding layer\n","        self.pos_embed_bool = pos_embed_bool\n","        if pos_embed_bool:\n","            self.pos_embed_dim=pos_embed_dim\n","            self.embedding_2 = nn.Embedding(\n","                num_embeddings=pos_vocab.size,\n","                embedding_dim=pos_embed_dim,\n","                padding_idx=padding_id,\n","                device=self.device\n","            )\n","        else:\n","            self.pos_embed_dim=0\n","        \n","        ### dropout layer\n","        self.drop_1=nn.Dropout(p=dropout)\n","        self.drop_2=nn.Dropout(p=dropout)\n","        \n","        # Recurrent layer type\n","        self.recurrent_type=recurrent_type\n","        if recurrent_type=='rnn':\n","            rec=nn.RNN\n","        elif recurrent_type=='gru':\n","            rec=nn.GRU\n","        else:\n","            rec=nn.LSTM\n","        ### intialise recrruent\n","        self.hidden_dim_lstm_fac=hidden_dim_lstm_fac\n","        if hidden_dim_lstm_fac==1:\n","            self.reduction=None\n","            self.rec = rec(\n","                input_size=embeddings.shape[1]+self.word_char_emb+self.pos_embed_dim,\n","                hidden_size=embeddings.shape[1]+self.word_char_emb+self.pos_embed_dim,\n","                num_layers=bilstm_layers,\n","                batch_first=True,\n","                dropout=dropout,\n","                bidirectional=True,\n","                device=self.device\n","            )\n","            \n","        else:\n","            self.reduction=nn.Linear(embeddings.shape[1]+self.word_char_emb+self.pos_embed_dim,int(hidden_dim_lstm_fac*(embeddings.shape[1]+self.word_char_emb+self.pos_embed_dim)),device=self.device)\n","            self.rec = rec(\n","                input_size=int(hidden_dim_lstm_fac*(embeddings.shape[1]+self.word_char_emb+self.pos_embed_dim)),\n","                hidden_size=int(hidden_dim_lstm_fac*(embeddings.shape[1]+self.word_char_emb+self.pos_embed_dim)),\n","                num_layers=bilstm_layers,\n","                batch_first=True,\n","                dropout=dropout,\n","                bidirectional=True,\n","                device=self.device\n","            )\n","            \n","         ### 1D CNN\n","        self.cnn_lstm_bool=cnn_lstm_bool\n","        if cnn_lstm_bool:\n","            self.cnn_lstm_out=nn.Sequential(*[nn.Conv1d(in_channels=1,out_channels=6,kernel_size=3,stride=2,device=self.device),nn.ReLU()])\n","\n","        # Projection layer\n","        self.projection = nn.LazyLinear(\n","            out_features=num_classes,\n","            device=self.device\n","        )\n","\n","        ### average over tokens check\n","        self.average_tokens=average_tokens\n","\n","    def forward(self, batch) -> torch.Tensor:\n","        # Get the different parts of the batch\n","        sequence_lengths,input_ids,pos_tag_ids = batch\n","        \n","        # First we embed the input tokens (spacy model)\n","        embeds = self.embedding(input_ids) # [B, S, H]\n","        # where B is the batch size, S is the sequence length and H is the hidden dimension\n","        \n","        ### POS embedding\n","        if self.pos_embed_bool:\n","            pos_tag_embeddings = self.embedding_2(pos_tag_ids)\n","            embeds = torch.cat((embeds, pos_tag_embeddings), dim=-1)  # Concatenate POS tag embeddings\n","            \n","        if self.char_embed_bool:\n","            ### character embedding:\n","            embeds_1=self.char_embedding(self.vocab,self.char_embed_dim, input_ids)\n","\n","            ### concantenate static + char embedding\n","            \n","            embeds=torch.cat((embeds,embeds_1),dim=2)\n","        \n","            \n","        ### DO dropout\n","        embeds-self.drop_1(embeds)\n","        \n","        \n","\n","        \n","        # An alternative to packing sequences is using masking.\n","        \n","        \n","        if self.hidden_dim_lstm_fac==1:\n","            # Pack the sequence to avoid gradient descent on padding tokens.\n","            packed = pack_padded_sequence(embeds, sequence_lengths, batch_first=True, enforce_sorted=False)\n","\n","            \n","            \n","            \n","            #### if recurrent layer is rnn or gru type\n","            if self.recurrent_type=='rnn' or self.recurrent_type=='gru':\n","                packed_output, hidden_state = self.rec(packed)\n","            \n","       \n","            else:\n","            ### if recurrent layyer is lstm type\n","                packed_output, (hidden_state, cell_state) = self.rec(packed)\n","            \n","        else:\n","            embeds=self.reduction(embeds)\n","            packed = pack_padded_sequence(embeds, sequence_lengths, batch_first=True, enforce_sorted=False)\n","\n","            #### if recurrent layer is rnn or gru type\n","            if self.recurrent_type=='rnn' or self.recurrent_type=='gru':\n","                packed_output, hidden_state = self.rec(packed)\n","            \n","            #### if recurrent layyer is lstm type\n","            else:\n","                packed_output, (hidden_state, cell_state) = self.rec(packed)\n","        \n","\n","        \n","        \n","        #### for the case sentence representation is computed using average of the tokens represenatation\n","        if self.average_tokens:\n","            sequence_lengths=sequence_lengths.to(self.device)\n","            ### create mask for pad tokens\n","            output=pad_packed_sequence(packed_output,batch_first=True)[0]\n","           \n","            mask = (torch.arange( output.size(1), device= output.device).expand( output.size(0),output.size(1)) < sequence_lengths.unsqueeze(1)).unsqueeze(2).repeat(1,1,output.shape[-1])\n","            \n","            ## sum over valid token\n","            sum_output=torch.sum(output*mask,dim=1)\n","\n","            \n","            ### take average along tokens\n","            \n","            hidden=sum_output/sequence_lengths.unsqueeze(1)  ###[B,H]\n","\n","        else:\n","            # We take the last two hidden representations of the BiLSTM (the second-to-last layer's output is forward; last\n","            # layer's is backward) by concatenating forward and backward over dimension 1.\n","            # Both tensors have shapes of [B, H], so concatenating them along the second dimension (dim 1) results in a new\n","            # tensor of shape [B, 2 * H]\n","            hidden = torch.cat((hidden_state[-2,:,:], hidden_state[-1,:,:]), dim = 1)\n","        ### apply dropout\n","        hidden=self.drop_2(hidden)\n","        ### pass thorugh 1D CNN\n","        if self.cnn_lstm_bool:\n","            hidden=self.cnn_lstm_out(hidden.unsqueeze(1))\n","            hidden=hidden.reshape(hidden.shape[0],-1)\n","\n","\n","        # Finally we project to the two final classes and return the logits of each class\n","        \n","        logits = self.projection(hidden) # [B, 2]\n","        return logits\n","    \n","    def char_embedding(self,vocab:Vocabulary,chr_emb_dim,sentences:torch.tensor):\n","        \n","        ### assuming max length of a token\n","        max_length=40\n","        ## Intialising character-level index matrix [Batch_size, Max_padded sequence length] ==>[Batch_size, Max_padded sequence length,\n","        # Max_length]\n","        word_char=torch.zeros((sentences.size(0),sentences.size(1),max_length))\n","        ###iterating over the batches\n","        for i in range(sentences.size(0)):\n","            ### iterating over the tokens in a sentence\n","            for j in range(sentences.size(1)):\n","\n","                word=self.vocab.itos[int(sentences[i,j])]\n","\n","                if word != '<pad>' and word != '<unk>':\n","                    ###getting indexes of the character in each token\n","                    char_ix=[self.char_dict[k] for k in word if k in list(self.char_dict.keys())  ]\n","                    ### the word length should of max max_length\n","\n","                    if len(char_ix) <=max_length:\n","                        word_char[i,j,0:len(char_ix)]=torch.LongTensor(char_ix)\n","\n","                    ### if it is bigger i take the first max_legnth elements to get the index of the characters\n","                    else:\n","                        word_char[i,j,:]=torch.LongTensor(char_ix)[0:max_length]\n","\n","        ### Intialiasing the character level embedding matrix [Batch_size, Max_padded sequence length,Charater-level-dimension]              \n","        word_emb=torch.zeros(word_char.size(0),word_char.size(1),self.char_embed_dim)\n","\n","        ### iterating over the batches\n","        for i in range(word_char.size(0)):\n","            ### getting embedding for the sequence of tokens in the sentence using character-level embedding [Max_seq_length,max_length,\n","            # character-level-dimension]\n","            e=self.embedding_1(word_char[i].long().to(self.device))\n","            e=e.unsqueeze(1)\n","            ##Convolution\n","\n","            con_e=self.cnn(e)\n","\n","            ### max pool [Max_seq_length,character-level-dimension] for each sentence in batch\n","            \n","            word_emb[i]=nn.functional.max_pool2d(con_e,kernel_size=(con_e.size(2), 1)).view(con_e.size(0), self.word_char_emb)\n","\n","        del(word_char)\n","        return(word_emb.to(self.device))"]},{"cell_type":"code","execution_count":21,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T18:58:48.854425Z","iopub.status.busy":"2024-05-03T18:58:48.854019Z","iopub.status.idle":"2024-05-03T18:58:48.884541Z","shell.execute_reply":"2024-05-03T18:58:48.883686Z","shell.execute_reply.started":"2024-05-03T18:58:48.854379Z"},"trusted":true},"outputs":[],"source":["class Trainer():\n","    \"\"\"Utility class to train and evaluate a model.\"\"\"\n","\n","    def __init__(\n","        self,\n","        model: nn.Module,\n","        optimizer: torch.optim.Optimizer,\n","        log_steps: int = 1_000,\n","        log_level: int = 2,\n","        patience: int = 4,  # Define the patience for early stopping\n","        use_best_weights:bool=False\n","    ):\n","        self.model = model\n","        self.optimizer = optimizer\n","        self.loss_function =nn.CrossEntropyLoss()\n","        self.log_steps = log_steps\n","        self.log_level = log_level\n","        \n","        \n","        ### early stopping\n","        self.patience = patience  # Store the patience value\n","        self.min_valid_loss = float('inf')  # Initialize the minimum validation loss\n","        self.best_train_loss = float('inf')  # Initialize the best training loss\n","        self.best_valid_acc = 0.0  # Initialize the best validation accuracy\n","        self.best_epoch = 0  # Initialize the epoch with the best validation loss\n","        self.num_bad_epochs = 0  # Counter for bad epochs\n","        \n","        ### save best weights\n","        self.use_best_weights=use_best_weights\n","        self.model_best_weights =None\n","        \n","    def train(\n","        self,\n","        train_dataloader: DataLoader,\n","        valid_dataloader: DataLoader,\n","        epochs: int = 1\n","    ) -> dict[str, list[float]]:\n","        \"\"\"\n","        Args:\n","            train_dataloader: a DataLoader instance containing the training instances.\n","            valid_dataloader: a DataLoader instance used to evaluate learning progress.\n","            epochs: the number of times to iterate over train_dataset.\n","\n","        Returns:\n","            avg_train_loss: the average training loss on train_dataset over epochs.\n","        \"\"\"\n","        assert epochs >= 1 and isinstance(epochs, int)\n","        if self.log_level > 0:\n","            print('Training ...')\n","        train_loss = 0.0\n","\n","        metrics = {\n","            \"train_losses\": [],\n","            \"valid_losses\": [],\n","            \"valid_acc\": [],\n","            'valid_f1':[],\n","            'valid_p':[],\n","            'valid_r':[]\n","        }\n","\n","        for epoch in range(1, epochs + 1):\n","\n","\n","            epoch_loss = 0.0\n","            self.model.train()\n","\n","            # for each batch\n","            for step, (sequence_lengths, inputs, labels,pos_tag_ids) in enumerate(train_dataloader):\n","                self.optimizer.zero_grad()\n","\n","                # We get the predicted logits from the model, with no need to perform any flattening\n","                # as both predictions and labels refer to the whole sentence.\n","                predictions = self.model((sequence_lengths, inputs,pos_tag_ids))\n","\n","                # The CrossEntropyLoss expects the predictions to be logits, i.e. non-softmaxed scores across\n","                sample_loss = self.loss_function(predictions, labels)\n","                ### loss backporp\n","                sample_loss.backward()\n","                self.optimizer.step()\n","                ###step loss\n","                epoch_loss += sample_loss.cpu().tolist()\n","\n","\n","            avg_epoch_loss = epoch_loss / len(train_dataloader)\n","\n","\n","            ### val metrics\n","            valid_loss, valid_acc, precision, recall, f1 = self.evaluate(valid_dataloader)\n","            ####Add results\n","\n","            metrics[\"train_losses\"].append(avg_epoch_loss)\n","            metrics[\"valid_losses\"].append(valid_loss)\n","            metrics[\"valid_acc\"].append(valid_acc)\n","            metrics['valid_f1'].append(f1)\n","            metrics['valid_p'].append(precision)\n","            metrics['valid_r'].append(recall)\n","            \n","\n","\n","            # Early stopping condition\n","            if valid_loss < self.min_valid_loss:\n","                self.min_valid_loss = valid_loss\n","                self.best_train_loss = avg_epoch_loss  # Update the best training loss\n","                self.best_valid_acc = valid_acc  # Update the best validation accuracy\n","                self.best_epoch = epoch  # Update the epoch with the best validation loss\n","                self.num_bad_epochs = 0  # Reset the counter if validation loss improves\n","                # Store the best model weights\n","                self.model_best_weights =deepcopy(self.model.state_dict())\n","            else:\n","                self.num_bad_epochs += 1\n","\n","            if self.num_bad_epochs >= self.patience:\n","                print(f\"Validation loss has not improved for {self.patience} epochs. Early stopping...\")\n","                break  # Stop training if early stopping condition is met\n","\n","        # Print the final best validation loss and corresponding training loss and validation accuracy\n","        print(f\"Best validation loss: {self.min_valid_loss}\")\n","        print(f\"Train loss at best validation: {self.best_train_loss}\")\n","        print(f\"Validation accuracy at best validation: {self.best_valid_acc}\")\n","\n","\n","        if self.log_level > 0:\n","            print('... Done!')\n","\n","        return metrics,self.best_epoch\n","\n","\n","    def _compute_acc(self, logits: torch.Tensor, labels: torch.Tensor) -> float:\n","        #compute prediction based on highest prob \n","        predictions = torch.argmax(logits, dim=1)\n","\n","        return torch.mean((predictions == labels).float()).tolist() # type: ignore\n","\n","    def evaluate(self, valid_dataloader: DataLoader,use_best_weights:bool=False) -> tuple[float, float]:\n","        \"\"\"\n","        Args:\n","            valid_dataloader: the DataLoader to use to evaluate the model.\n","            use_best_weights:if the trainer should use the best weights\n","\n","        Returns:\n","            avg_valid_loss: the average validation loss over valid_dataloader.\n","        \"\"\"\n","        valid_loss = 0.0\n","        valid_acc = 0.0\n","        y_true = []\n","        y_pred = []\n","        \n","        ### check for uasge of best weights\n","        self.use_best_weights=use_best_weights\n","        if self.use_best_weights and self.model_best_weights is not None:\n","                # Load the best model weights\n","                print('Loading best weights')\n","                self.model.load_state_dict(self.model_best_weights)\n","        \n","        ### eval mode\n","        self.model.eval()\n","        with torch.no_grad():\n","            \n","            for batch in valid_dataloader:\n","                sequence_lengths, inputs, labels,pos_tag_ids = batch\n","                \n","                logits = self.model((sequence_lengths, inputs,pos_tag_ids))\n","        \n","                # Same considerations as the training step apply here\n","                sample_loss = self.loss_function(logits, labels)\n","                valid_loss += sample_loss.tolist()\n","        \n","                sample_acc = self._compute_acc(logits, labels)\n","                valid_acc += sample_acc\n","\n","                # Convert logits to predictions\n","                predictions = torch.argmax(logits, dim=1)\n","                y_true.extend(labels.cpu().numpy())\n","                y_pred.extend(predictions.cpu().numpy())\n","\n","        # Compute precision, recall, and F1 score\n","        precision = precision_score(y_true, y_pred, average='macro')\n","        recall = recall_score(y_true, y_pred, average='macro')\n","        f1 = f1_score(y_true, y_pred, average='macro')\n","\n","        return valid_loss / len(valid_dataloader), valid_acc / len(valid_dataloader), precision, recall, f1\n","\n","    def predict(self, batch: tuple[torch.Tensor, torch.Tensor]) -> tuple[torch.Tensor, torch.Tensor]:\n","        \"\"\"\n","        Args:\n","            x: a tensor of indices\n","        Returns:\n","            A tuple composed of:\n","            - the logits of each class, 0 and 1\n","            - the prediction for each sample in the batch\n","              0 if the sentiment of the sentence is negative, 1 if it is positive.\n","        \"\"\"\n","        self.model.eval()\n","        with torch.no_grad():\n","            sequence_lengths, inputs = batch\n","            logits = self.model(sequence_lengths, inputs) # [B, 2]\n","            predictions = torch.argmax(logits, -1) # [B, 1] computed on the last dimension of the logits tensor\n","            return logits, predictions"]},{"cell_type":"markdown","metadata":{},"source":["> ### Note: Hyper Param Search\n","> #### The code is bit messy for the search but it's optimised for performance.I make sure no two iterations are redundant"]},{"cell_type":"code","execution_count":8,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:01:32.733978Z","iopub.status.busy":"2024-05-03T19:01:32.733577Z","iopub.status.idle":"2024-05-03T19:01:32.789702Z","shell.execute_reply":"2024-05-03T19:01:32.788581Z","shell.execute_reply.started":"2024-05-03T19:01:32.733949Z"},"trusted":true},"outputs":[],"source":["def Hyper_param_search():\n","    \"\"\"\n","    Perform Hyperparameter search for main model.\n","    \n","    \"\"\"\n","    \n","    ### use char_emb\n","    char_emb_space=[True,False]\n","    \n","    ### char_embedding_dim soace\n","    char_emb_dim_space=[30,50]\n","    \n","    ### character kernel size\n","    char_kernel_size_space=[2,5]\n","    \n","    ### pos tag_emb\n","    pos_emb_space=[True,False]\n","    ## pos tag embedding size\n","    pos_emb_dim_space=[30,50]\n","    \n","    #### dropout\n","    dropout_space=[0.3,0.5]\n","    \n","    #### rec layer type\n","    rec_space=['rnn','gru','lstm']\n","    \n","    #### lr \n","    lr_space=[1e-3,1e-4]\n","    \n","    ### weight decay\n","    weight_decay_space=[1e-4,1e-3]\n","    \n","    ### average tokens\n","    average_tokens_space=[True,False]\n","    \n","    #### 1D CNN at rec output\n","    cnn_lstm_space=[True,False]\n","    \n","    #### epochs\n","    max_epochs=50\n","    \n","\n","    current_iteration = 0\n","    \n","    \n","    results=pd.DataFrame(columns=['param_space','metrics','best_epoch'])\n","#     results=pd.read_csv('/kaggle/input/hyper-param-intermediate-results/hyper_param_search_updated_inter.csv')\n","    \n","    for char_emb in char_emb_space:\n","        if char_emb:     \n","            for char_emb_dim in char_emb_dim_space:\n","                    for char_kernel_size in char_kernel_size_space:\n","                        for pos_emb in pos_emb_space:\n","                            ### if pos embedding being used\n","                            \n","                                if pos_emb:\n","                                    for pos_emb_dim in pos_emb_dim_space:\n","                                        for dropout in dropout_space:\n","                                            for rec_layer_type in rec_space:\n","                                                for lr in lr_space:\n","                                                    for weight_decay in weight_decay_space:\n","                                                        for average_tokens in average_tokens_space:\n","                                                            for cnn_lstm in cnn_lstm_space:\n","                                                                current_iteration += 1\n","                                                                set_seed(seed)\n","                                                                print(f\"Iteration {current_iteration}\")\n","                                                                # Perform hyperparameter search here\n","                                                                # Construct the configuration and train the model\n","                                                                config = {\n","                                                                    \"char_emb\": char_emb,\n","                                                                    \"char_emb_dim\": char_emb_dim,\n","                                                                    \"char_kernel_size\": char_kernel_size,\n","                                                                    \"pos_emb\": pos_emb,\n","                                                                    \"pos_emb_dim\": pos_emb_dim,\n","                                                                    \"dropout\": dropout,\n","                                                                    \"rec_layer_type\": rec_layer_type,\n","                                                                    \"lr\": lr,\n","                                                                    \"weight_decay\": weight_decay,\n","                                                                    \"average_tokens\": average_tokens,\n","                                                                    \"cnn_lstm\": cnn_lstm\n","                                                                }\n","                                                                \n","                                                                if str(config) not in list(results.param_space.values):\n","                                                                    ####  perform one iteration of search\n","                                                                    print(\"Current model configuration and params:\", config)\n","\n","                                                                    torch.cuda.empty_cache()\n","\n","                                                                    sentiment_tagger =model_v1(\n","                                                                        vocab_it,\n","                                                                        embeddings,\n","                                                                        hidden_dim_lstm_fac=1,\n","                                                                        bilstm_layers=2,\n","                                                                        dropout=dropout,\n","                                                                        num_classes=3,\n","                                                                        padding_id=0,\n","                                                                        freeze_embedding=True,\n","                                                                        char_embed_dim=char_emb_dim,\n","                                                                        char_embed_bool=char_emb,\n","                                                                        char_kernel_size=char_kernel_size,\n","                                                                        cnn_lstm_bool=cnn_lstm,\n","                                                                        average_tokens=average_tokens,\n","                                                                        char_dict=char_dict,\n","                                                                    pos_vocab=pos_vocab,\n","                                                                    pos_embed_dim=pos_emb_dim,\n","                                                                    pos_embed_bool=pos_emb,\n","                                                                    recurrent_type=rec_layer_type)\n","\n","\n","\n","                                                                    ### setup trainer\n","                                                                    trainer = Trainer(\n","                                                                        model=sentiment_tagger,\n","                                                                        optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad,sentiment_tagger.parameters()), lr=lr,weight_decay=weight_decay),\n","                                                                        log_steps=100,patience=4\n","                                                                    )\n","                                                                    ###metrics\n","                                                                    metrics,best_epoch = trainer.train(train_dataloader, val_dataloader, epochs=max_epochs)\n","                                                                    #### \n","                                                                    print('precision:{},recall:{},f1_score:{}'.format(metrics['valid_p'][best_epoch],metrics['valid_r'][best_epoch],metrics['valid_f1'][best_epoch]))\n","                                                                    results.loc[len(results)]=[config,metrics,best_epoch]\n","                                                                    results.to_csv('./data/hyper_param_search_main.csv',index=False)\n","                                else:\n","#                                         char_kernel_size=0\n","                                        \n","                                        pos_emb_dim=0\n","                                        for dropout in dropout_space:\n","                                                for rec_layer_type in rec_space:\n","                                                    for lr in lr_space:\n","                                                        for weight_decay in weight_decay_space:\n","                                                            for average_tokens in average_tokens_space:\n","                                                                for cnn_lstm in cnn_lstm_space:\n","                                                                    current_iteration += 1\n","                                                                    set_seed(seed)\n","                                                                    print(f\"Iteration {current_iteration}\")\n","                                                                    # Perform hyperparameter search here\n","                                                                    # Construct the configuration and train the model\n","                                                                    config = {\n","                                                                        \"char_emb\": char_emb,\n","                                                                        \"char_emb_dim\": char_emb_dim,\n","                                                                        \"char_kernel_size\": char_kernel_size,\n","                                                                        \"pos_emb\": pos_emb,\n","                                                                        \"pos_emb_dim\": pos_emb_dim,\n","                                                                        \"dropout\": dropout,\n","                                                                        \"rec_layer_type\": rec_layer_type,\n","                                                                        \"lr\": lr,\n","                                                                        \"weight_decay\": weight_decay,\n","                                                                        \"average_tokens\": average_tokens,\n","                                                                        \"cnn_lstm\": cnn_lstm\n","                                                                    }\n","\n","                                                                    if str(config) not in list(results.param_space.values):\n","                                                                        ####  perform one iteration of search\n","                                                                        print(\"Current configuration:\", config)\n","                                                                        torch.cuda.empty_cache()\n","\n","                                                                        sentiment_tagger =model_v1(\n","                                                                            vocab_it,\n","                                                                            embeddings,\n","                                                                            hidden_dim_lstm_fac=1,\n","                                                                            bilstm_layers=2,\n","                                                                            dropout=dropout,\n","                                                                            num_classes=3,\n","                                                                            padding_id=0,\n","                                                                            freeze_embedding=True,\n","                                                                            char_embed_dim=char_emb_dim,\n","                                                                            char_embed_bool=char_emb,\n","                                                                            char_kernel_size=char_kernel_size,\n","                                                                            cnn_lstm_bool=cnn_lstm,\n","                                                                            average_tokens=average_tokens,\n","                                                                            char_dict=char_dict,\n","                                                                        pos_vocab=pos_vocab,\n","                                                                        pos_embed_dim=pos_emb_dim,\n","                                                                        pos_embed_bool=pos_emb,\n","                                                                        recurrent_type=rec_layer_type)\n","\n","\n","\n","                                                                        ### setup trainer\n","                                                                        trainer = Trainer(\n","                                                                            model=sentiment_tagger,\n","                                                                            optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad,sentiment_tagger.parameters()), lr=lr,weight_decay=weight_decay),\n","                                                                            log_steps=100,patience=4\n","                                                                        )\n","                                                                        ###metrics\n","                                                                        metrics,best_epoch = trainer.train(train_dataloader, val_dataloader, epochs=max_epochs)\n","                                                                        #### \n","                                                                        print('precision:{},recall:{},f1_score:{}'.format(metrics['valid_p'][best_epoch],metrics['valid_r'][best_epoch],metrics['valid_f1'][best_epoch]))\n","                                                                        results.loc[len(results)]=[config,metrics,best_epoch]\n","                                                                        results.to_csv('./data/hyper_param_search_main.csv',index=False)\n","\n","        else:\n","            char_emb_dim=0\n","            char_kernel_size=0\n","            for pos_emb in pos_emb_space:\n","                            ### if pos embedding being used\n","                            \n","                                if pos_emb:\n","                                    for pos_emb_dim in pos_emb_dim_space:\n","                                        for dropout in dropout_space:\n","                                            for rec_layer_type in rec_space:\n","                                                for lr in lr_space:\n","                                                    for weight_decay in weight_decay_space:\n","                                                        for average_tokens in average_tokens_space:\n","                                                            for cnn_lstm in cnn_lstm_space:\n","                                                                current_iteration += 1\n","                                                                set_seed(seed)\n","                                                                \n","                                                                print(f\"Iteration {current_iteration}\")\n","                                                                \n","                                                                \n","                                                                 # Construct the configuration and train the model\n","                                                                config = {\n","                                                                        \"char_emb\": char_emb,\n","                                                                        \"char_emb_dim\": char_emb_dim,\n","                                                                        \"char_kernel_size\": char_kernel_size,\n","                                                                        \"pos_emb\": pos_emb,\n","                                                                        \"pos_emb_dim\": pos_emb_dim,\n","                                                                        \"dropout\": dropout,\n","                                                                        \"rec_layer_type\": rec_layer_type,\n","                                                                        \"lr\": lr,\n","                                                                        \"weight_decay\": weight_decay,\n","                                                                        \"average_tokens\": average_tokens,\n","                                                                        \"cnn_lstm\": cnn_lstm\n","                                                                    }\n","\n","                                                                if str(config)not in list(results.param_space.values):\n","                                                                    print(\"Current configuration:\", config)\n","                                                                    ####  perform one iteration of search\n","                                                                    torch.cuda.empty_cache()\n","\n","                                                                    sentiment_tagger =model_v1(\n","                                                                        vocab_it,\n","                                                                        embeddings,\n","                                                                        hidden_dim_lstm_fac=1,\n","                                                                        bilstm_layers=2,\n","                                                                        dropout=dropout,\n","                                                                        num_classes=3,\n","                                                                        padding_id=0,\n","                                                                        freeze_embedding=True,\n","                                                                        char_embed_dim=char_emb_dim,\n","                                                                        char_embed_bool=char_emb,\n","                                                                        char_kernel_size=char_kernel_size,\n","                                                                        cnn_lstm_bool=cnn_lstm,\n","                                                                        average_tokens=average_tokens,\n","                                                                        char_dict=char_dict,\n","                                                                    pos_vocab=pos_vocab,\n","                                                                    pos_embed_dim=pos_emb_dim,\n","                                                                    pos_embed_bool=pos_emb,\n","                                                                    recurrent_type=rec_layer_type)\n","\n","\n","\n","                                                                    ### setup trainer\n","                                                                    trainer = Trainer(\n","                                                                        model=sentiment_tagger,\n","                                                                        optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad,sentiment_tagger.parameters()), lr=lr,weight_decay=weight_decay),\n","                                                                        log_steps=100,patience=4\n","                                                                    )\n","                                                                    ###metrics\n","                                                                    metrics,best_epoch = trainer.train(train_dataloader, val_dataloader, epochs=max_epochs)\n","                                                                    #### \n","                                                                    print('precision:{},recall:{},f1_score:{}'.format(metrics['valid_p'][best_epoch],metrics['valid_r'][best_epoch],metrics['valid_f1'][best_epoch]))\n","                                                                    results.loc[len(results)]=[config,metrics,best_epoch]\n","                                                                    results.to_csv('./data/hyper_param_search_main.csv',index=False)\n","                                else:\n","                                        pos_emb_dim=0\n","                                        for dropout in dropout_space:\n","                                                for rec_layer_type in rec_space:\n","                                                    for lr in lr_space:\n","                                                        for weight_decay in weight_decay_space:\n","                                                            for average_tokens in average_tokens_space:\n","                                                                for cnn_lstm in cnn_lstm_space:\n","                                                                    current_iteration += 1\n","                                                                    set_seed(seed)\n","                                                                    print(f\"Iteration {current_iteration}\")\n","                                                                    # Perform hyperparameter search here\n","                                                                    # Construct the configuration and train the model\n","                                                                    config = {\n","                                                                        \"char_emb\": char_emb,\n","                                                                        \"char_emb_dim\": char_emb_dim,\n","                                                                        \"char_kernel_size\": char_kernel_size,\n","                                                                        \"pos_emb\": pos_emb,\n","                                                                        \"pos_emb_dim\": pos_emb_dim,\n","                                                                        \"dropout\": dropout,\n","                                                                        \"rec_layer_type\": rec_layer_type,\n","                                                                        \"lr\": lr,\n","                                                                        \"weight_decay\": weight_decay,\n","                                                                        \"average_tokens\": average_tokens,\n","                                                                        \"cnn_lstm\": cnn_lstm\n","                                                                    }\n","                                                                    if str(config) not in list(results.param_space.values):\n","                                                                        ####  perform one iteration of search\n","                                                                        print(\"Current configuration:\", config)\n","                                                                        torch.cuda.empty_cache()\n","\n","                                                                        sentiment_tagger =model_v1(\n","                                                                            vocab_it,\n","                                                                            embeddings,\n","                                                                            hidden_dim_lstm_fac=1,\n","                                                                            bilstm_layers=2,\n","                                                                            dropout=dropout,\n","                                                                            num_classes=3,\n","                                                                            padding_id=0,\n","                                                                            freeze_embedding=True,\n","                                                                            char_embed_dim=char_emb_dim,\n","                                                                            char_embed_bool=char_emb,\n","                                                                            char_kernel_size=char_kernel_size,\n","                                                                            cnn_lstm_bool=cnn_lstm,\n","                                                                            average_tokens=average_tokens,\n","                                                                            char_dict=char_dict,\n","                                                                        pos_vocab=pos_vocab,\n","                                                                        pos_embed_dim=pos_emb_dim,\n","                                                                        pos_embed_bool=pos_emb,\n","                                                                        recurrent_type=rec_layer_type)\n","\n","\n","\n","                                                                        ### setup trainer\n","                                                                        trainer = Trainer(\n","                                                                            model=sentiment_tagger,\n","                                                                            optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad,sentiment_tagger.parameters()), lr=lr,weight_decay=weight_decay),\n","                                                                            log_steps=100,patience=4\n","                                                                        )\n","                                                                        ###metrics\n","                                                                        metrics,best_epoch = trainer.train(train_dataloader, val_dataloader, epochs=max_epochs)\n","                                                                        #### \n","                                                                        print('precision:{},recall:{},f1_score:{}'.format(metrics['valid_p'][best_epoch],metrics['valid_r'][best_epoch],metrics['valid_f1'][best_epoch]))\n","                                                                        results.loc[len(results)]=[config,metrics,best_epoch]\n","                                                                        results.to_csv('./data/hyper_param_search_main.csv',index=False)\n","\n","                                                \n","    \n","    \n","    \n","    \n","    "]},{"cell_type":"markdown","metadata":{},"source":["### Run Hyper param search for the main model"]},{"cell_type":"markdown","metadata":{},"source":["> #### Only run if you want to reporduce results as it would take around 20 hours for completion"]},{"cell_type":"code","execution_count":74,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T12:36:53.944899Z","iopub.status.busy":"2024-05-03T12:36:53.944073Z","iopub.status.idle":"2024-05-03T12:36:53.948525Z","shell.execute_reply":"2024-05-03T12:36:53.947484Z","shell.execute_reply.started":"2024-05-03T12:36:53.944868Z"},"trusted":true},"outputs":[],"source":["# Hyper_param_search()"]},{"cell_type":"markdown","metadata":{},"source":["### Reading the stored results"]},{"cell_type":"code","execution_count":6,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:02:11.827035Z","iopub.status.busy":"2024-05-03T19:02:11.826243Z","iopub.status.idle":"2024-05-03T19:02:11.892417Z","shell.execute_reply":"2024-05-03T19:02:11.891441Z","shell.execute_reply.started":"2024-05-03T19:02:11.826997Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>param_space</th>\n","      <th>metrics</th>\n","      <th>best_epoch</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>{'char_emb': True, 'char_emb_dim': 30, 'char_k...</td>\n","      <td>{'train_losses': [1.0597900322505407, 0.984651...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>{'char_emb': True, 'char_emb_dim': 30, 'char_k...</td>\n","      <td>{'train_losses': [1.1237637911524092, 0.976582...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>{'char_emb': True, 'char_emb_dim': 30, 'char_k...</td>\n","      <td>{'train_losses': [1.075956608567919, 0.9492638...</td>\n","      <td>2</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>{'char_emb': True, 'char_emb_dim': 30, 'char_k...</td>\n","      <td>{'train_losses': [1.1552448783602034, 0.898589...</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>{'char_emb': True, 'char_emb_dim': 30, 'char_k...</td>\n","      <td>{'train_losses': [1.0596617545400346, 0.987529...</td>\n","      <td>3</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>1435</th>\n","      <td>{'char_emb': False, 'char_emb_dim': 0, 'char_k...</td>\n","      <td>{'train_losses': [1.0702060801642281, 1.037001...</td>\n","      <td>8</td>\n","    </tr>\n","    <tr>\n","      <th>1436</th>\n","      <td>{'char_emb': False, 'char_emb_dim': 0, 'char_k...</td>\n","      <td>{'train_losses': [1.0686750071389335, 1.046038...</td>\n","      <td>12</td>\n","    </tr>\n","    <tr>\n","      <th>1437</th>\n","      <td>{'char_emb': False, 'char_emb_dim': 0, 'char_k...</td>\n","      <td>{'train_losses': [1.0700206415993827, 1.042821...</td>\n","      <td>10</td>\n","    </tr>\n","    <tr>\n","      <th>1438</th>\n","      <td>{'char_emb': False, 'char_emb_dim': 0, 'char_k...</td>\n","      <td>{'train_losses': [1.068851547581809, 1.0435801...</td>\n","      <td>13</td>\n","    </tr>\n","    <tr>\n","      <th>1439</th>\n","      <td>{'char_emb': False, 'char_emb_dim': 0, 'char_k...</td>\n","      <td>{'train_losses': [1.0711471693856376, 1.038292...</td>\n","      <td>10</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>1440 rows × 3 columns</p>\n","</div>"],"text/plain":["                                            param_space  \\\n","0     {'char_emb': True, 'char_emb_dim': 30, 'char_k...   \n","1     {'char_emb': True, 'char_emb_dim': 30, 'char_k...   \n","2     {'char_emb': True, 'char_emb_dim': 30, 'char_k...   \n","3     {'char_emb': True, 'char_emb_dim': 30, 'char_k...   \n","4     {'char_emb': True, 'char_emb_dim': 30, 'char_k...   \n","...                                                 ...   \n","1435  {'char_emb': False, 'char_emb_dim': 0, 'char_k...   \n","1436  {'char_emb': False, 'char_emb_dim': 0, 'char_k...   \n","1437  {'char_emb': False, 'char_emb_dim': 0, 'char_k...   \n","1438  {'char_emb': False, 'char_emb_dim': 0, 'char_k...   \n","1439  {'char_emb': False, 'char_emb_dim': 0, 'char_k...   \n","\n","                                                metrics  best_epoch  \n","0     {'train_losses': [1.0597900322505407, 0.984651...           3  \n","1     {'train_losses': [1.1237637911524092, 0.976582...           3  \n","2     {'train_losses': [1.075956608567919, 0.9492638...           2  \n","3     {'train_losses': [1.1552448783602034, 0.898589...           1  \n","4     {'train_losses': [1.0596617545400346, 0.987529...           3  \n","...                                                 ...         ...  \n","1435  {'train_losses': [1.0702060801642281, 1.037001...           8  \n","1436  {'train_losses': [1.0686750071389335, 1.046038...          12  \n","1437  {'train_losses': [1.0700206415993827, 1.042821...          10  \n","1438  {'train_losses': [1.068851547581809, 1.0435801...          13  \n","1439  {'train_losses': [1.0711471693856376, 1.038292...          10  \n","\n","[1440 rows x 3 columns]"]},"execution_count":6,"metadata":{},"output_type":"execute_result"}],"source":["df_main_hyper_results=pd.read_csv('./data/hyper_param_results_main.csv')\n","df_main_hyper_results"]},{"cell_type":"markdown","metadata":{},"source":["# Selection of Hyper-param based on Validation Acc"]},{"cell_type":"code","execution_count":25,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:02:28.366431Z","iopub.status.busy":"2024-05-03T19:02:28.366031Z","iopub.status.idle":"2024-05-03T19:02:29.473996Z","shell.execute_reply":"2024-05-03T19:02:29.473021Z","shell.execute_reply.started":"2024-05-03T19:02:28.366381Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The best Hyperparameter combination is:  {'char_emb': True, 'char_emb_dim': 30, 'char_kernel_size': 5, 'pos_emb': False, 'pos_emb_dim': 0, 'dropout': 0.3, 'rec_layer_type': 'lstm', 'lr': 0.0001, 'weight_decay': 0.0001, 'average_tokens': True, 'cnn_lstm': False}\n","Validation acc achived by the selected combination of Hyperparameters:  0.5718845278024673\n","Validation loss achived by the selected combination of Hyperparameters:  1.000121369957924\n"]}],"source":["\n","df_main_hyper_results['val_acc']=df_main_hyper_results.apply(lambda x:eval(x.metrics)['valid_acc'][x.best_epoch-1],axis=1)\n","df_main_hyper_results['val_f1']=df_main_hyper_results.apply(lambda x:eval(x.metrics)['valid_f1'][x.best_epoch-1],axis=1)\n","df_main_hyper_results['val_loss']=df_main_hyper_results.apply(lambda x:eval(x.metrics)['valid_losses'][x.best_epoch-1],axis=1)\n","# Sort the DataFrame by val_acc in decreasing order\n","df_main_hyper_results = df_main_hyper_results.sort_values(by='val_acc', ascending=False)\n","\n","# Display the sorted DataFrame\n","print('The best Hyperparameter combination is: ',df_main_hyper_results.iloc[0].param_space)\n","print('Validation acc achived by the selected combination of Hyperparameters: ',df_main_hyper_results.iloc[0].val_acc)\n","print('Validation loss achived by the selected combination of Hyperparameters: ',eval(df_main_hyper_results.iloc[0].metrics)['valid_losses'][df_main_hyper_results.iloc[0].best_epoch-1])\n","      "]},{"cell_type":"markdown","metadata":{},"source":["# Top-6 configurations"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T17:00:02.130734Z","iopub.status.busy":"2024-05-03T17:00:02.129998Z","iopub.status.idle":"2024-05-03T17:00:05.575105Z","shell.execute_reply":"2024-05-03T17:00:05.573913Z","shell.execute_reply.started":"2024-05-03T17:00:02.130700Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>char_emb</th>\n","      <th>char_emb_dim</th>\n","      <th>char_kernel_size</th>\n","      <th>pos_emb</th>\n","      <th>pos_emb_dim</th>\n","      <th>dropout</th>\n","      <th>rec_layer_type</th>\n","      <th>lr</th>\n","      <th>weight_decay</th>\n","      <th>average_tokens</th>\n","      <th>cnn_lstm</th>\n","      <th>train_losses</th>\n","      <th>valid_losses</th>\n","      <th>valid_acc</th>\n","      <th>valid_f1</th>\n","      <th>valid_p</th>\n","      <th>valid_r</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>True</td>\n","      <td>30</td>\n","      <td>5</td>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>0.3</td>\n","      <td>lstm</td>\n","      <td>0.0001</td>\n","      <td>0.0001</td>\n","      <td>True</td>\n","      <td>False</td>\n","      <td>0.818308</td>\n","      <td>1.000121</td>\n","      <td>0.571885</td>\n","      <td>0.491523</td>\n","      <td>0.534694</td>\n","      <td>0.497053</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>True</td>\n","      <td>50</td>\n","      <td>5</td>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>0.5</td>\n","      <td>lstm</td>\n","      <td>0.0010</td>\n","      <td>0.0010</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.919731</td>\n","      <td>0.972899</td>\n","      <td>0.570408</td>\n","      <td>0.448133</td>\n","      <td>0.573763</td>\n","      <td>0.471597</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>0</td>\n","      <td>True</td>\n","      <td>50</td>\n","      <td>0.3</td>\n","      <td>rnn</td>\n","      <td>0.0001</td>\n","      <td>0.0010</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.834105</td>\n","      <td>1.000253</td>\n","      <td>0.566263</td>\n","      <td>0.483951</td>\n","      <td>0.549332</td>\n","      <td>0.483134</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>True</td>\n","      <td>30</td>\n","      <td>2</td>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>0.3</td>\n","      <td>gru</td>\n","      <td>0.0001</td>\n","      <td>0.0001</td>\n","      <td>False</td>\n","      <td>True</td>\n","      <td>0.778053</td>\n","      <td>0.995906</td>\n","      <td>0.564548</td>\n","      <td>0.441720</td>\n","      <td>0.498993</td>\n","      <td>0.464273</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>True</td>\n","      <td>30</td>\n","      <td>2</td>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>0.5</td>\n","      <td>gru</td>\n","      <td>0.0001</td>\n","      <td>0.0001</td>\n","      <td>True</td>\n","      <td>True</td>\n","      <td>0.860648</td>\n","      <td>0.994787</td>\n","      <td>0.564310</td>\n","      <td>0.436012</td>\n","      <td>0.569453</td>\n","      <td>0.464305</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>True</td>\n","      <td>50</td>\n","      <td>2</td>\n","      <td>False</td>\n","      <td>0</td>\n","      <td>0.5</td>\n","      <td>lstm</td>\n","      <td>0.0010</td>\n","      <td>0.0001</td>\n","      <td>False</td>\n","      <td>False</td>\n","      <td>0.835726</td>\n","      <td>1.018561</td>\n","      <td>0.562357</td>\n","      <td>0.478181</td>\n","      <td>0.537060</td>\n","      <td>0.476600</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   char_emb  char_emb_dim  char_kernel_size  pos_emb  pos_emb_dim  dropout  \\\n","0      True            30                 5    False            0      0.3   \n","1      True            50                 5    False            0      0.5   \n","2     False             0                 0     True           50      0.3   \n","3      True            30                 2    False            0      0.3   \n","4      True            30                 2    False            0      0.5   \n","5      True            50                 2    False            0      0.5   \n","\n","  rec_layer_type      lr  weight_decay  average_tokens  cnn_lstm  \\\n","0           lstm  0.0001        0.0001            True     False   \n","1           lstm  0.0010        0.0010            True      True   \n","2            rnn  0.0001        0.0010            True      True   \n","3            gru  0.0001        0.0001           False      True   \n","4            gru  0.0001        0.0001            True      True   \n","5           lstm  0.0010        0.0001           False     False   \n","\n","   train_losses  valid_losses  valid_acc  valid_f1   valid_p   valid_r  \n","0      0.818308      1.000121   0.571885  0.491523  0.534694  0.497053  \n","1      0.919731      0.972899   0.570408  0.448133  0.573763  0.471597  \n","2      0.834105      1.000253   0.566263  0.483951  0.549332  0.483134  \n","3      0.778053      0.995906   0.564548  0.441720  0.498993  0.464273  \n","4      0.860648      0.994787   0.564310  0.436012  0.569453  0.464305  \n","5      0.835726      1.018561   0.562357  0.478181  0.537060  0.476600  "]},"execution_count":40,"metadata":{},"output_type":"execute_result"}],"source":["keys=list(eval(df_main_hyper_results.iloc[0].param_space).keys())\n","keys+=list(eval(df_main_hyper_results.iloc[0].metrics).keys())\n","df_hyper_param_table_main=pd.DataFrame(columns=keys)\n","for _,j in df_main_hyper_results.iterrows():\n","    row=[i for k,i in enumerate(eval(j.param_space).values())]\n","    row+=[i[j.best_epoch-1] for v,i in enumerate(eval(j.metrics).values())]\n","    df_hyper_param_table_main.loc[len(df_hyper_param_table_main)]=row\n","df_hyper_param_table_main.head(6)"]},{"cell_type":"markdown","metadata":{},"source":["# Re-train model with the best hyper-param"]},{"cell_type":"code","execution_count":26,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:03:23.294030Z","iopub.status.busy":"2024-05-03T19:03:23.293537Z","iopub.status.idle":"2024-05-03T19:04:45.907691Z","shell.execute_reply":"2024-05-03T19:04:45.906597Z","shell.execute_reply.started":"2024-05-03T19:03:23.293997Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n","  warnings.warn('Lazy modules are a new feature under heavy development '\n"]},{"name":"stdout","output_type":"stream","text":["Training ...\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n","/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]},{"name":"stdout","output_type":"stream","text":["Validation loss has not improved for 4 epochs. Early stopping...\n","Best validation loss: 1.000121369957924\n","Train loss at best validation: 0.8183079021317619\n","Validation accuracy at best validation: 0.5718845278024673\n","... Done!\n"]}],"source":["torch.cuda.empty_cache()  \n","set_seed(seed)\n","### best_config\n","config=eval(df_main_hyper_results.iloc[0].param_space)\n","### intialise the model\n","sentiment_tagger =model_v1(\n","                            vocab_it,\n","                            embeddings,\n","                            hidden_dim_lstm_fac=1,\n","                            bilstm_layers=2,\n","                            dropout=config['dropout'],\n","                            num_classes=3,\n","                            padding_id=0,\n","                            freeze_embedding=True,\n","                            char_embed_dim=config['char_emb_dim'],\n","                            char_embed_bool=config['char_emb'],\n","                            char_kernel_size=config['char_kernel_size'],\n","                            cnn_lstm_bool=config['cnn_lstm'],\n","                            average_tokens=config['average_tokens'],\n","                            char_dict=char_dict,\n","                        pos_vocab=pos_vocab,\n","                        pos_embed_dim=config['pos_emb_dim'],\n","                        pos_embed_bool=config['pos_emb'],\n","                        recurrent_type=config['rec_layer_type'])\n","\n","\n","\n","### setup trainer\n","trainer_main = Trainer(\n","    model=sentiment_tagger,\n","    optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad,sentiment_tagger.parameters()), lr=config['lr'],weight_decay=config['weight_decay']),\n","    log_steps=100,patience=4\n",")\n","###metrics\n","metrics,best_epoch = trainer_main.train(train_dataloader, val_dataloader, epochs=400)"]},{"cell_type":"markdown","metadata":{},"source":["# "]},{"cell_type":"markdown","metadata":{},"source":["# Final Model Structure"]},{"cell_type":"code","execution_count":27,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:04:45.910458Z","iopub.status.busy":"2024-05-03T19:04:45.909886Z","iopub.status.idle":"2024-05-03T19:04:45.916313Z","shell.execute_reply":"2024-05-03T19:04:45.915196Z","shell.execute_reply.started":"2024-05-03T19:04:45.910395Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model_v1(\n","  (embedding): Embedding(681836, 300, padding_idx=0)\n","  (embedding_1): Embedding(116, 30)\n","  (cnn): Conv2d(1, 30, kernel_size=(5, 30), stride=(1, 1))\n","  (drop_1): Dropout(p=0.3, inplace=False)\n","  (drop_2): Dropout(p=0.3, inplace=False)\n","  (rec): LSTM(330, 330, num_layers=2, batch_first=True, dropout=0.3, bidirectional=True)\n","  (projection): Linear(in_features=660, out_features=3, bias=True)\n",")\n"]}],"source":["print(trainer_main.model)"]},{"cell_type":"markdown","metadata":{},"source":["### Validation Set Performance"]},{"cell_type":"code","execution_count":28,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:04:45.918635Z","iopub.status.busy":"2024-05-03T19:04:45.918212Z","iopub.status.idle":"2024-05-03T19:04:46.669693Z","shell.execute_reply":"2024-05-03T19:04:46.668605Z","shell.execute_reply.started":"2024-05-03T19:04:45.918598Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading best weights\n","The results on the val data: test_loss:1.000121369957924,test_acc:0.5718845278024673,precision:0.5346938898143724,recall:0.497052567239638,f1_score:0.4915225923702038\n"]}],"source":["#### load best model and get the performance on validation set\n","metrics_val_main=trainer_main.evaluate(val_dataloader,True)\n","print('The results on the val data: test_loss:{},test_acc:{},precision:{},recall:{},f1_score:{}'.format(*metrics_val_main))"]},{"cell_type":"markdown","metadata":{},"source":["### Test set performance"]},{"cell_type":"code","execution_count":29,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:04:46.672813Z","iopub.status.busy":"2024-05-03T19:04:46.672341Z","iopub.status.idle":"2024-05-03T19:04:48.655569Z","shell.execute_reply":"2024-05-03T19:04:48.654475Z","shell.execute_reply.started":"2024-05-03T19:04:46.672773Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading best weights\n","The results on the test data: test_loss:0.8459055688646104,test_acc:0.6487806836764017,precision:0.5105711511223316,recall:0.48776838510744364,f1_score:0.4945147105489822\n"]}],"source":["metrics_test_main=trainer_main.evaluate(test_dataloader,True)\n","print('The results on the test data: test_loss:{},test_acc:{},precision:{},recall:{},f1_score:{}'.format(*metrics_test_main))"]},{"cell_type":"markdown","metadata":{},"source":["# Model-2- Static Embedding+NN"]},{"cell_type":"code","execution_count":34,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:09:56.925295Z","iopub.status.busy":"2024-05-03T19:09:56.924881Z","iopub.status.idle":"2024-05-03T19:09:56.942644Z","shell.execute_reply":"2024-05-03T19:09:56.941462Z","shell.execute_reply.started":"2024-05-03T19:09:56.925255Z"},"trusted":true},"outputs":[],"source":["#### Model-1 Fixed Embedding[static+NN]\n","class model_simple(torch.nn.Module):\n","\n","    def __init__(\n","        self,\n","        vocabulary: Vocabulary,\n","        embeddings:np.array,\n","        dropout: float,\n","        num_classes: int,\n","        padding_id: int,\n","        freeze_embedding:bool,\n","        add_linear:bool,\n","        linear_hid_fac:float,\n","        device: str = \"cuda\",\n","    ) -> None:\n","        super().__init__()\n","\n","        # Prepare the device\n","        self.device = torch.device(device)\n","        \n","        #### vocabulary\n","        self.vocab=vocabulary\n","\n","        # Embedding layer\n","        self.embedding = nn.Embedding(\n","            num_embeddings=vocabulary.size+2,\n","            embedding_dim=embeddings.shape[1],\n","            padding_idx=padding_id, # avoid updating the gradient of padding entries\n","            device=self.device\n","        )\n","         #Load weights from the NumPy array\n","        self.embedding.weight.data.copy_(torch.from_numpy(embeddings))\n","        if freeze_embedding:\n","            self.embedding.weight.requires_grad=False\n","\n","        \n","        ### dropout layer\n","        self.drop_1=nn.Dropout(p=dropout)\n","        self.drop_2=nn.Dropout(p=dropout)\n","       \n","        #### Add linear layers\n","        self.add_linear=add_linear\n","        \n","        if self.add_linear:\n","            self.linear=nn.Sequential(*[nn.Linear(embeddings.shape[1],int(embeddings.shape[1]*linear_hid_fac),device=self.device),nn.ReLU()])\n","        # Projection layer\n","        self.projection = nn.LazyLinear(\n","            out_features=num_classes,\n","            device=self.device\n","        )\n","\n","    def forward(self, batch) -> torch.Tensor:\n","        # Get the different parts of the batch\n","        sequence_lengths,input_ids,pos_tag_ids = batch\n","        \n","        # First we embed the input tokens (spacy model)\n","        embeds = self.embedding(input_ids) # [B, S, H]\n","        # where B is the batch size, S is the sequence length and H is the hidden dimension\n","       \n","        ### DO dropout\n","        output=self.drop_1(embeds)\n","        \n","        ### if non-linear before[Linear+RelU]\n","        \n","    \n","        \n","        \n","        #### for the getting the sentence representation we compute average of the tokens word_embedding\n","        sequence_lengths=sequence_lengths.to(self.device)\n","        ### create mask for pad tokens\n","        mask = (torch.arange( output.size(1), device= output.device).expand( output.size(0),output.size(1)) < sequence_lengths.unsqueeze(1)).unsqueeze(2).repeat(1,1,output.shape[-1])\n","\n","        ## sum over valid token across tokens axis\n","        sum_output=torch.sum(output*mask,dim=1)\n","#             max_output=torch.max(output*mask,dim=1).values\n","\n","        ### take average along tokens\n","\n","        hidden=sum_output/sequence_lengths.unsqueeze(1)  ###[B,H]\n","\n","        ### apply dropout\n","        hidden=self.drop_2(hidden)\n","        ### apply non linear layer\n","        if self.add_linear:\n","            output=self.linear(output)\n","        # Finally we project to the three final classes and return the logits of each class\n","        logits = self.projection(hidden) # [B, 2]\n","        return logits\n","    \n","    "]},{"cell_type":"code","execution_count":10,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:09:57.276803Z","iopub.status.busy":"2024-05-03T19:09:57.276413Z","iopub.status.idle":"2024-05-03T19:09:57.296390Z","shell.execute_reply":"2024-05-03T19:09:57.295345Z","shell.execute_reply.started":"2024-05-03T19:09:57.276774Z"},"trusted":true},"outputs":[],"source":["def Hyper_param_search_simple():\n","    \n","    \"\"\"\n","    Perform Hyperparameter search for simple model.\n","    \n","    \"\"\"\n","    \n","    #### dropout\n","    dropout_space=[0.3,0.5]\n","    \n","   \n","\n","    #### lr \n","    lr_space=[1e-3,1e-4]\n","    \n","    ### weight decay\n","    weight_decay_space=[1e-4,1e-3]\n","    \n","    ### add linear\n","    add_linear_space=[True,False]\n","    \n","    ### linear output dim fac wrt to input\n","    linear_hid_fac_space=[0.5,1,1.5,2]\n","    \n","    \n","    results=pd.DataFrame(columns=['param_space','metrics','best_epoch'])\n","    for add_linear in add_linear_space:\n","        if add_linear==True:\n","            for linear_hid_fac in linear_hid_fac_space:\n","                for p in dropout_space:\n","                    for lr in lr_space:\n","                        for weight_decay in weight_decay_space:\n","                            config = {\n","                                        \"dropout\": p,\n","                                        \"lr\": lr,\n","                                        \"weight_decay\": weight_decay,\n","                                         'add_linear':add_linear,\n","                                         'linear_hid_fac':linear_hid_fac\n","                                        }\n","                            print(\"Current configuration:\", config)\n","                            set_seed(seed)\n","                            torch.cuda.empty_cache()    \n","                            sentiment_tagger =model_simple(\n","                                                vocab_it,\n","                                                embeddings,\n","                                                dropout=p,\n","                                                num_classes=3,\n","                                                padding_id=0,\n","                                                freeze_embedding=True,\n","                                                add_linear=add_linear,\n","                                                linear_hid_fac=linear_hid_fac\n","                            )\n","\n","\n","\n","                            ### setup trainer\n","                            trainer = Trainer(\n","                                model=sentiment_tagger,\n","                                optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad,sentiment_tagger.parameters()), lr=1e-4,weight_decay=1e-4),\n","                                log_steps=100,patience=4\n","                            )\n","                            ###metrics\n","                            metrics,best_epoch = trainer.train(train_dataloader, val_dataloader, epochs=400)\n","\n","\n","\n","                    print('precision:{},recall:{},f1_score:{}'.format(metrics['valid_p'][best_epoch],metrics['valid_r'][best_epoch],metrics['valid_f1'][best_epoch]))\n","                    results.loc[len(results)]=[config,metrics,best_epoch]\n","                    results.to_csv('./data/hyper_param_search_simple.csv',index=False)\n","        else:\n","                linear_hid_fac='None'\n","                for p in dropout_space:\n","                    for lr in lr_space:\n","                        for weight_decay in weight_decay_space:\n","                            set_seed(seed)\n","                            config = {\n","                                        \"dropout\": p,\n","                                        \"lr\": lr,\n","                                        \"weight_decay\": weight_decay,\n","                                         'add_linear':add_linear,\n","                                         'linear_hid_fac':linear_hid_fac\n","                                        }\n","                            print(\"Current configuration:\", config)\n","                            torch.cuda.empty_cache()    \n","                            sentiment_tagger =model_simple(\n","                                                vocab_it,\n","                                                embeddings,\n","                                                dropout=p,\n","                                                num_classes=3,\n","                                                padding_id=0,\n","                                                freeze_embedding=True,\n","                                                add_linear=add_linear,\n","                                                linear_hid_fac=linear_hid_fac\n","                            )\n","\n","\n","\n","                            ### setup trainer\n","                            trainer = Trainer(\n","                                model=sentiment_tagger,\n","                                optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad,sentiment_tagger.parameters()), lr=1e-4,weight_decay=1e-4),\n","                                log_steps=100,patience=4\n","                            )\n","                            ###metrics\n","                            metrics,best_epoch = trainer.train(train_dataloader, val_dataloader, epochs=400)\n","\n","\n","\n","                    print('precision:{},recall:{},f1_score:{}'.format(metrics['valid_p'][best_epoch],metrics['valid_r'][best_epoch],metrics['valid_f1'][best_epoch]))\n","                    results.loc[len(results)]=[config,metrics,best_epoch]\n","                    results.to_csv('/data/hyper_param_search_simple.csv',index=False)\n","\n","    \n","    \n","    \n","    \n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Run Hyper-param-search for Simpler model\n","\n","> ### Quite fast"]},{"cell_type":"code","execution_count":36,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:09:58.230637Z","iopub.status.busy":"2024-05-03T19:09:58.230059Z","iopub.status.idle":"2024-05-03T19:09:58.234940Z","shell.execute_reply":"2024-05-03T19:09:58.233756Z","shell.execute_reply.started":"2024-05-03T19:09:58.230608Z"},"trusted":true},"outputs":[],"source":["# Hyper_param_search_simple()"]},{"cell_type":"markdown","metadata":{},"source":["# "]},{"cell_type":"markdown","metadata":{},"source":["# Selection of Hyper-param based on Validation Acc"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:10:05.818175Z","iopub.status.busy":"2024-05-03T19:10:05.817790Z","iopub.status.idle":"2024-05-03T19:10:05.890256Z","shell.execute_reply":"2024-05-03T19:10:05.889273Z","shell.execute_reply.started":"2024-05-03T19:10:05.818144Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The best Hyperparameter combination is:  {'dropout': 0.3, 'lr': 0.0001, 'weight_decay': 0.001, 'add_linear': False, 'linear_hid_fac': 'None'}\n","Validation acc achived by the selected combination of Hyperparameters:  0.5372046381235123\n","Validation loss achived by the selected combination of Hyperparameters:  0.9980201423168182\n"]}],"source":["df_results_simple=pd.read_csv('./data/hyper_param_search_simple.csv')\n","df_results_simple['val_acc']=df_results_simple.apply(lambda x:eval(x.metrics)['valid_acc'][x.best_epoch-1],axis=1)\n","df_results_simple['val_f1']=df_results_simple.apply(lambda x:eval(x.metrics)['valid_f1'][x.best_epoch-1],axis=1)\n","\n","# Sort the DataFrame by val_acc in decreasing order\n","df_results_simple = df_results_simple.sort_values(by='val_acc', ascending=False)\n","\n","\n","print('The best Hyperparameter combination is: ',df_results_simple.iloc[0].param_space)\n","print('Validation acc achived by the selected combination of Hyperparameters: ',df_results_simple.iloc[0].val_acc)\n","print('Validation loss achived by the selected combination of Hyperparameters: ',eval(df_results_simple.iloc[0].metrics)['valid_losses'][df_results_simple.iloc[0].best_epoch-1])\n"," "]},{"cell_type":"markdown","metadata":{},"source":["### Top-6 Model configurations"]},{"cell_type":"code","execution_count":38,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:10:08.016948Z","iopub.status.busy":"2024-05-03T19:10:08.016083Z","iopub.status.idle":"2024-05-03T19:10:08.084979Z","shell.execute_reply":"2024-05-03T19:10:08.083993Z","shell.execute_reply.started":"2024-05-03T19:10:08.016916Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>dropout</th>\n","      <th>lr</th>\n","      <th>weight_decay</th>\n","      <th>add_linear</th>\n","      <th>linear_hid_fac</th>\n","      <th>train_losses</th>\n","      <th>valid_losses</th>\n","      <th>valid_acc</th>\n","      <th>valid_f1</th>\n","      <th>valid_p</th>\n","      <th>valid_r</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>0.3</td>\n","      <td>0.0001</td>\n","      <td>0.001</td>\n","      <td>False</td>\n","      <td>None</td>\n","      <td>0.987682</td>\n","      <td>0.998020</td>\n","      <td>0.537205</td>\n","      <td>0.369471</td>\n","      <td>0.477315</td>\n","      <td>0.407775</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>0.5</td>\n","      <td>0.0001</td>\n","      <td>0.001</td>\n","      <td>True</td>\n","      <td>0.5</td>\n","      <td>1.015314</td>\n","      <td>1.009075</td>\n","      <td>0.527201</td>\n","      <td>0.328412</td>\n","      <td>0.534136</td>\n","      <td>0.386224</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>0.5</td>\n","      <td>0.0001</td>\n","      <td>0.001</td>\n","      <td>True</td>\n","      <td>1.5</td>\n","      <td>1.015314</td>\n","      <td>1.009075</td>\n","      <td>0.527201</td>\n","      <td>0.328412</td>\n","      <td>0.534136</td>\n","      <td>0.386224</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>0.5</td>\n","      <td>0.0001</td>\n","      <td>0.001</td>\n","      <td>True</td>\n","      <td>1</td>\n","      <td>1.015314</td>\n","      <td>1.009075</td>\n","      <td>0.527201</td>\n","      <td>0.328412</td>\n","      <td>0.534136</td>\n","      <td>0.386224</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>0.5</td>\n","      <td>0.0001</td>\n","      <td>0.001</td>\n","      <td>False</td>\n","      <td>None</td>\n","      <td>1.047423</td>\n","      <td>1.010087</td>\n","      <td>0.525486</td>\n","      <td>0.318113</td>\n","      <td>0.549777</td>\n","      <td>0.378064</td>\n","    </tr>\n","    <tr>\n","      <th>5</th>\n","      <td>0.5</td>\n","      <td>0.0001</td>\n","      <td>0.001</td>\n","      <td>True</td>\n","      <td>2</td>\n","      <td>1.018718</td>\n","      <td>1.010378</td>\n","      <td>0.515006</td>\n","      <td>0.316398</td>\n","      <td>0.518706</td>\n","      <td>0.378467</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   dropout      lr  weight_decay  add_linear linear_hid_fac  train_losses  \\\n","0      0.3  0.0001         0.001       False           None      0.987682   \n","1      0.5  0.0001         0.001        True            0.5      1.015314   \n","2      0.5  0.0001         0.001        True            1.5      1.015314   \n","3      0.5  0.0001         0.001        True              1      1.015314   \n","4      0.5  0.0001         0.001       False           None      1.047423   \n","5      0.5  0.0001         0.001        True              2      1.018718   \n","\n","   valid_losses  valid_acc  valid_f1   valid_p   valid_r  \n","0      0.998020   0.537205  0.369471  0.477315  0.407775  \n","1      1.009075   0.527201  0.328412  0.534136  0.386224  \n","2      1.009075   0.527201  0.328412  0.534136  0.386224  \n","3      1.009075   0.527201  0.328412  0.534136  0.386224  \n","4      1.010087   0.525486  0.318113  0.549777  0.378064  \n","5      1.010378   0.515006  0.316398  0.518706  0.378467  "]},"execution_count":38,"metadata":{},"output_type":"execute_result"}],"source":["keys = list(eval(df_results_simple.iloc[0].param_space).keys())\n","keys += list(eval(df_results_simple.iloc[0].metrics).keys())\n","df_hyper_param_table_simple = pd.DataFrame(columns=keys)\n","\n","for _, j in df_results_simple.iterrows():\n","    row = [i for k, i in enumerate(eval(j.param_space).values())]\n","    row += [i[j.best_epoch - 1] for v, i in enumerate(eval(j.metrics).values())]\n","    df_hyper_param_table_simple.loc[len(df_hyper_param_table_simple)] = row\n","\n","df_hyper_param_table_simple.head(6)\n"]},{"cell_type":"markdown","metadata":{},"source":["# Re-train model with the best hyper-param"]},{"cell_type":"code","execution_count":39,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:10:09.597341Z","iopub.status.busy":"2024-05-03T19:10:09.596980Z","iopub.status.idle":"2024-05-03T19:10:34.236854Z","shell.execute_reply":"2024-05-03T19:10:34.235801Z","shell.execute_reply.started":"2024-05-03T19:10:09.597314Z"},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/torch/nn/modules/lazy.py:180: UserWarning: Lazy modules are a new feature under heavy development so changes to the API or functionality can happen at any moment.\n","  warnings.warn('Lazy modules are a new feature under heavy development '\n"]},{"name":"stdout","output_type":"stream","text":["Training ...\n","Validation loss has not improved for 4 epochs. Early stopping...\n","Best validation loss: 0.9980262964963913\n","Train loss at best validation: 0.9876272976398468\n","Validation accuracy at best validation: 0.5372046381235123\n","... Done!\n"]}],"source":["torch.cuda.empty_cache()  \n","set_seed(seed)\n","### best_config\n","config=eval(df_results_simple.iloc[0].param_space)\n","sentiment_tagger =model_simple(\n","                    vocab_it,\n","                    embeddings,\n","                    dropout=config['dropout'],\n","                    num_classes=3,\n","                    padding_id=0,\n","                    freeze_embedding=True,\n","                    add_linear=config['add_linear'],\n","                    linear_hid_fac=config['linear_hid_fac']\n",")\n","\n","\n","\n","\n","### setup trainer\n","trainer_simple = Trainer(\n","    model=sentiment_tagger,\n","    optimizer=torch.optim.Adam(filter(lambda p: p.requires_grad,sentiment_tagger.parameters()), lr=config['lr'],weight_decay=config['weight_decay']),\n","    log_steps=100,patience=4\n",")\n","###metrics\n","metrics,best_epoch = trainer_simple.train(train_dataloader, val_dataloader, epochs=400)"]},{"cell_type":"markdown","metadata":{},"source":["# Final Simple Model Structure\n"]},{"cell_type":"code","execution_count":40,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:10:34.239691Z","iopub.status.busy":"2024-05-03T19:10:34.239082Z","iopub.status.idle":"2024-05-03T19:10:34.245532Z","shell.execute_reply":"2024-05-03T19:10:34.244362Z","shell.execute_reply.started":"2024-05-03T19:10:34.239652Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["model_simple(\n","  (embedding): Embedding(681836, 300, padding_idx=0)\n","  (drop_1): Dropout(p=0.3, inplace=False)\n","  (drop_2): Dropout(p=0.3, inplace=False)\n","  (projection): Linear(in_features=300, out_features=3, bias=True)\n",")\n"]}],"source":["print(trainer_simple.model)"]},{"cell_type":"markdown","metadata":{},"source":["### Validation Performance"]},{"cell_type":"code","execution_count":41,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:10:34.247139Z","iopub.status.busy":"2024-05-03T19:10:34.246833Z","iopub.status.idle":"2024-05-03T19:10:34.308232Z","shell.execute_reply":"2024-05-03T19:10:34.307121Z","shell.execute_reply.started":"2024-05-03T19:10:34.247114Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading best weights\n","The results on the val data: test_loss:0.9980262964963913,test_acc:0.5372046381235123,precision:0.4773145410342335,recall:0.4077750859659455,f1_score:0.36947070136945787\n"]}],"source":["#### load best model and get the performance on validation set\n","metrics_val_simple=trainer_simple.evaluate(val_dataloader,True)\n","print('The results on the val data: test_loss:{},test_acc:{},precision:{},recall:{},f1_score:{}'.format(*metrics_val_simple))"]},{"cell_type":"markdown","metadata":{},"source":["### Test Performance"]},{"cell_type":"code","execution_count":50,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:12:14.829142Z","iopub.status.busy":"2024-05-03T19:12:14.828380Z","iopub.status.idle":"2024-05-03T19:12:14.948597Z","shell.execute_reply":"2024-05-03T19:12:14.947462Z","shell.execute_reply.started":"2024-05-03T19:12:14.829111Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Loading best weights\n","The results on the test data: test_loss:0.873625722196367,test_acc:0.6691093312369453,precision:0.5008966587476607,recall:0.4305138905057415,f1_score:0.43216027065200663\n"]}],"source":["metrics_test_simple=trainer_simple.evaluate(test_dataloader,True)\n","print('The results on the test data: test_loss:{},test_acc:{},precision:{},recall:{},f1_score:{}'.format(*metrics_test_simple))"]},{"cell_type":"markdown","metadata":{},"source":["# Baseline Model-Stratified Sampling"]},{"cell_type":"code","execution_count":42,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:11:25.031009Z","iopub.status.busy":"2024-05-03T19:11:25.030625Z","iopub.status.idle":"2024-05-03T19:11:25.051350Z","shell.execute_reply":"2024-05-03T19:11:25.050358Z","shell.execute_reply.started":"2024-05-03T19:11:25.030980Z"},"trusted":true},"outputs":[],"source":["#### Model-1 Fixed Embedding[static+BILSTM+Projection layer]\n","class model_baseline_stratified(torch.nn.Module):\n","\n","    def __init__(\n","        self,\n","        class_weights:torch.tensor,\n","        device: str = \"cuda\",\n","    ) -> None:\n","        super().__init__()\n","\n","        # Prepare the device\n","        self.device = torch.device(device)\n","        ### Class weights\n","        self.class_weights=class_weights\n","        self.class_weights.to(self.device)\n","\n","    def forward(self, batch_size) -> torch.Tensor:\n","        #### BAsed on stratified sampliing\n","        #### \n","        prob= torch.rand(batch_size)\n","        \n","        ### assign labels\n","        labels=torch.tensor([self.assign_class(i) for i in prob])\n","        \n","        return labels\n","    def assign_class(self,x):\n","        if x<class_weights[0]:\n","            return 0\n","        elif (x>class_weights[0]) and (x<class_weights[1]):\n","            return 1\n","        else:\n","            return 2\n","        \n","    \n","class Trainer_baseline():\n","     def __init__(\n","        self,\n","        model: nn.Module,\n","    ):\n","        self.model = model\n","        self.loss_function =nn.CrossEntropyLoss()\n","    \n","     def train(\n","        self,\n","        train_dataloader: DataLoader,\n","        valid_dataloader: DataLoader,\n","        epochs: int = 1\n","    ) -> dict[str, list[float]]:\n","        \"\"\"\n","        Args:\n","            train_dataloader: a DataLoader instance containing the training instances.\n","            valid_dataloader: a DataLoader instance used to evaluate learning progress.\n","            epochs: the number of times to iterate over train_dataset.\n","\n","        Returns:\n","            avg_train_loss: the average training loss on train_dataset over epochs.\n","        \"\"\"\n","       \n","        print('Training ...')\n","        train_loss = 0.0\n","\n","        metrics = {\n","            \"valid_acc\": [],\n","            'valid_f1':[],\n","            'valid_p':[],\n","            'valid_r':[]\n","        }\n","\n","\n","        valid_acc, precision, recall, f1 = self.evaluate(valid_dataloader)\n","\n","#\n","        metrics[\"valid_acc\"].append(valid_acc)\n","        metrics['valid_f1'].append(f1)\n","        metrics['valid_p'].append(precision)\n","        metrics['valid_r'].append(recall)\n","\n","\n","        print('... Done!')\n","\n","        return metrics\n","\n","\n","     def _compute_acc(self, logits: torch.Tensor, labels: torch.Tensor) -> float:\n","\n","        predictions = logits\n","\n","        return torch.mean((predictions == labels.cpu()).float()).tolist() # type: ignore\n","\n","     def evaluate(self, valid_dataloader: DataLoader) -> tuple[float, float]:\n","        \"\"\"\n","        Args:\n","            valid_dataloader: the DataLoader to use to evaluate the model.\n","\n","        Returns:\n","            avg_valid_loss: the average validation loss over valid_dataloader.\n","        \"\"\"\n","        valid_loss = 0.0\n","        valid_acc = 0.0\n","        y_true = []\n","        y_pred = []\n","        # When running in inference mode, it is required to have model.eval() AND .no_grad()\n","        # Among other things, these set dropout to 0 and turn off gradient computation.\n","\n","        for batch in valid_dataloader:\n","            sequence_lengths, inputs, labels,pos_tag_ids = batch\n","\n","            logits = self.model((inputs.size(0)))\n","\n","            sample_acc = self._compute_acc(logits, labels)\n","            valid_acc += sample_acc\n","\n","            predictions =logits\n","\n","            y_true.extend(labels.cpu().numpy())\n","            y_pred.extend(predictions.cpu().numpy())\n","\n","        # Compute precision, recall, and F1 score\n","        \n","        precision = precision_score(y_true, y_pred, average='macro')\n","        recall = recall_score(y_true, y_pred, average='macro')\n","        f1 = f1_score(y_true, y_pred, average='macro')\n","\n","        return  valid_acc / len(valid_dataloader), precision, recall, f1\n","\n","     def predict(self, batch: tuple[torch.Tensor, torch.Tensor]) -> tuple[torch.Tensor, torch.Tensor]:\n","        \"\"\"\n","        Args:\n","            x: a tensor of indices\n","        Returns:\n","            A tuple composed of:\n","            - the logits of each class, 0 and 1\n","            - the prediction for each sample in the batch\n","              0 if the sentiment of the sentence is negative, 1 if it is positive.\n","        \"\"\"\n","        self.model.eval()\n","        with torch.no_grad():\n","            sequence_lengths, inputs = batch\n","            logits = self.model(sequence_lengths, inputs) # [B, 2]\n","            predictions = torch.argmax(logits, -1) # [B, 1] computed on the last dimension of the logits tensor\n","            return logits, predictions\n","    \n","    "]},{"cell_type":"markdown","metadata":{},"source":["# Setup Baseline Model and Trainer"]},{"cell_type":"code","execution_count":46,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:11:57.447076Z","iopub.status.busy":"2024-05-03T19:11:57.446692Z","iopub.status.idle":"2024-05-03T19:11:57.456079Z","shell.execute_reply":"2024-05-03T19:11:57.454890Z","shell.execute_reply.started":"2024-05-03T19:11:57.447049Z"},"trusted":true},"outputs":[],"source":["set_seed(seed)\n","torch.cuda.empty_cache()\n","class_weights=torch.tensor(train_data.labels.value_counts().values/sum(train_data.labels.value_counts().values))\n","sentiment_tagger = model_baseline_stratified(class_weights)\n","\n","\n","\n","### setup trainer\n","trainer_baseline = Trainer_baseline(\n","    model=sentiment_tagger\n",")\n","\n","\n"]},{"cell_type":"markdown","metadata":{},"source":["### Baseline Validation Performance"]},{"cell_type":"code","execution_count":47,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:11:58.942730Z","iopub.status.busy":"2024-05-03T19:11:58.942320Z","iopub.status.idle":"2024-05-03T19:11:59.008455Z","shell.execute_reply":"2024-05-03T19:11:59.007353Z","shell.execute_reply.started":"2024-05-03T19:11:58.942699Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The results on the val data: test_acc:0.39148247241973877,precision:0.2406571973080817,recall:0.33259136474859896,f1_score:0.27519224029521516\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["metrics_val_baseline=trainer_baseline.evaluate(val_dataloader)\n","print('The results on the val data: test_acc:{},precision:{},recall:{},f1_score:{}'.format(*metrics_val_baseline))"]},{"cell_type":"markdown","metadata":{},"source":["### Baseline Test Performance"]},{"cell_type":"code","execution_count":48,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:11:59.815181Z","iopub.status.busy":"2024-05-03T19:11:59.814316Z","iopub.status.idle":"2024-05-03T19:11:59.954221Z","shell.execute_reply":"2024-05-03T19:11:59.953190Z","shell.execute_reply.started":"2024-05-03T19:11:59.815148Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["The results on the test data: test_acc:0.41850371493233574,precision:0.2872736616479481,recall:0.3597076829854364,f1_score:0.28080774904648387\n"]},{"name":"stderr","output_type":"stream","text":["/opt/conda/lib/python3.10/site-packages/sklearn/metrics/_classification.py:1344: UndefinedMetricWarning: Precision is ill-defined and being set to 0.0 in labels with no predicted samples. Use `zero_division` parameter to control this behavior.\n","  _warn_prf(average, modifier, msg_start, len(result))\n"]}],"source":["\n","metrics_test_baseline=trainer_baseline.evaluate(test_dataloader)\n","\n","print('The results on the test data: test_acc:{},precision:{},recall:{},f1_score:{}'.format(*metrics_test_baseline))"]},{"cell_type":"markdown","metadata":{},"source":["# Final Results Table"]},{"cell_type":"code","execution_count":51,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:12:20.186623Z","iopub.status.busy":"2024-05-03T19:12:20.185902Z","iopub.status.idle":"2024-05-03T19:12:20.203561Z","shell.execute_reply":"2024-05-03T19:12:20.202590Z","shell.execute_reply.started":"2024-05-03T19:12:20.186590Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>Model</th>\n","      <th>Validation Accuracy</th>\n","      <th>Validation Macro F1</th>\n","      <th>Test Accuracy</th>\n","      <th>Test Macro F1</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>Baseline</td>\n","      <td>0.240657</td>\n","      <td>0.275192</td>\n","      <td>0.287274</td>\n","      <td>0.280808</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>Simple model</td>\n","      <td>0.537205</td>\n","      <td>0.369471</td>\n","      <td>0.669109</td>\n","      <td>0.432160</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>Main model</td>\n","      <td>0.571885</td>\n","      <td>0.491523</td>\n","      <td>0.648781</td>\n","      <td>0.494515</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["          Model  Validation Accuracy  Validation Macro F1  Test Accuracy  \\\n","0      Baseline             0.240657             0.275192       0.287274   \n","1  Simple model             0.537205             0.369471       0.669109   \n","2    Main model             0.571885             0.491523       0.648781   \n","\n","   Test Macro F1  \n","0       0.280808  \n","1       0.432160  \n","2       0.494515  "]},"execution_count":51,"metadata":{},"output_type":"execute_result"}],"source":["metrics_main = ['Main model',metrics_val_main[1], metrics_val_main[-1], metrics_test_main[1], metrics_test_main[-1]]\n","metrics_simple = ['Simple model',metrics_val_simple[1], metrics_val_simple[-1], metrics_test_simple[1], metrics_test_simple[-1]]\n","metrics_baseline = ['Baseline',metrics_val_baseline[1], metrics_val_baseline[-1], metrics_test_baseline[1], metrics_test_baseline[-1]]\n","\n","final_compare_results = pd.DataFrame([metrics_baseline, metrics_simple, metrics_main],\n","                                     columns=['Model','Validation Accuracy', 'Validation Macro F1', 'Test Accuracy', 'Test Macro F1'])\n","final_compare_results"]},{"cell_type":"markdown","metadata":{},"source":["# Compute Confusion Matrix\n","\n","> #### Main Model\n","> #### Simple Model"]},{"cell_type":"code","execution_count":54,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:13:57.801934Z","iopub.status.busy":"2024-05-03T19:13:57.801520Z","iopub.status.idle":"2024-05-03T19:14:00.029271Z","shell.execute_reply":"2024-05-03T19:14:00.028221Z","shell.execute_reply.started":"2024-05-03T19:13:57.801905Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["\n"," \n","def compute_cm(dataloader: DataLoader,model) -> tuple[float, float]:\n","        \"\"\"\n","        Args:\n","            valid_dataloader: the DataLoader to use to evaluate the model.\n","\n","        Returns:\n","            avg_valid_loss: the average validation loss over valid_dataloader.\n","        \"\"\"\n","        valid_loss = 0.0\n","        valid_acc = 0.0\n","        y_true = []\n","        y_pred = []\n","        # When running in inference mode, it is required to have model.eval() AND .no_grad()\n","        # Among other things, these set dropout to 0 and turn off gradient computation.\n","        model.eval()\n","        with torch.no_grad():\n","            for batch in dataloader:\n","                sequence_lengths, inputs, labels,pos_tag_ids = batch\n","\n","                logits = model((sequence_lengths, inputs,pos_tag_ids))\n","                \n","                predictions = torch.argmax(logits, dim=1)\n","\n","                y_true.extend(labels.cpu().numpy())\n","                y_pred.extend(predictions.cpu().numpy())\n","        cm = confusion_matrix(y_true, y_pred)\n","                # Assuming cm_main is your confusion matrix and class_labels is a list of class labels\n","        class_labels = [\"Against\", \"Favor\", \"Neutral\"]  # Example labels, replace with your actual class labels\n","\n","        # Plot the heatmap with labels on the axes\n","        sns.heatmap(cm, annot=True, fmt='d', xticklabels=class_labels, yticklabels=class_labels)\n","\n","        # Add labels to the axes\n","        plt.xlabel('Predicted Label')\n","        plt.ylabel('True Label')\n","\n","        # Show the plot\n","        plt.show()\n","\n","compute_cm(test_dataloader,trainer_main.model)\n"]},{"cell_type":"code","execution_count":55,"metadata":{"execution":{"iopub.execute_input":"2024-05-03T19:14:00.031284Z","iopub.status.busy":"2024-05-03T19:14:00.030958Z","iopub.status.idle":"2024-05-03T19:14:00.450328Z","shell.execute_reply":"2024-05-03T19:14:00.449419Z","shell.execute_reply.started":"2024-05-03T19:14:00.031256Z"},"trusted":true},"outputs":[{"data":{"image/png":"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","text/plain":["<Figure size 640x480 with 2 Axes>"]},"metadata":{},"output_type":"display_data"}],"source":["compute_cm(test_dataloader,trainer_simple.model)"]}],"metadata":{"accelerator":"GPU","colab":{"gpuType":"T4","provenance":[]},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"datasetId":4886138,"sourceId":8237509,"sourceType":"datasetVersion"},{"datasetId":4925278,"sourceId":8291128,"sourceType":"datasetVersion"},{"datasetId":4927411,"sourceId":8300332,"sourceType":"datasetVersion"},{"datasetId":4931162,"sourceId":8300410,"sourceType":"datasetVersion"},{"datasetId":4932959,"sourceId":8303812,"sourceType":"datasetVersion"}],"dockerImageVersionId":30699,"isGpuEnabled":true,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.12"}},"nbformat":4,"nbformat_minor":4}
